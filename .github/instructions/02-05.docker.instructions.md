---
description: "Instructions for Docker and Docker Compose configuration"
applyTo: "**/*.yml"
---
# Docker Configuration Instructions

- Follow [Docker Compose docs](https://docs.docker.com/compose/) for standard practices
- Prefer command directives over scripts; use container networking, secrets, and explicit port mappings as needed
- Use `docker compose` (not `docker-compose`)

## Docker Compose Cross-Platform Path Requirements

**CRITICAL: Path configuration for cross-platform compatibility**

- **NEVER use absolute paths** in `deployments/compose/compose.yml`
- **ALWAYS use relative paths** for all file references (volumes, secrets, configs, dockerfiles)
- Absolute Windows paths (`C:\...`) break cross-platform compatibility with:
  - GitHub Actions Ubuntu runners
  - `act` local workflow testing on Windows/WSL
  - Docker Compose path resolution in Linux containers
- Relative paths resolve correctly from the compose file's directory on all platforms

**Example corrections:**
- ❌ BAD: `file: C:\Dev\Projects\cryptoutil\deployments\compose\postgres\postgres_username.secret`
- ✅ GOOD: `file: ./postgres/postgres_username.secret`

**Applies to ALL path references in compose.yml:**
- Secret file references
- Volume mount paths
- Config file references
- Dockerfile paths

## Multi-Stage Build Best Practices

### ARG Scoping Rules
- **Global ARGs**: Declare all build parameters at the top of Dockerfile for visibility and overrideability
- **Stage ARGs**: Redeclare ARGs in stages where they're used in LABEL instructions (Docker requirement)
- **Required ARGs**: Use validation stages to enforce mandatory build arguments
- **LABEL Placement**: Put ALL LABELs on final published image, not intermediate stages
- **Build ARGs**: Move build-specific ARGs (CGO_ENABLED, GOOS, etc.) to global section for consistency

### WORKDIR Best Practices
- **Builder Stage**: Use `/src` for source code location (Go ecosystem standard)
- **Runtime Stage**: Use `/app` for application runtime (clear separation)
- **Avoid Mixing**: Don't use same WORKDIR for source and final application
- **Git Safety**: `/src` avoids git ownership issues that can occur with `/app`

### Required Build Arguments
Dockerfile now enforces `VCS_REF` and `BUILD_DATE` as mandatory:

```dockerfile
ARG VCS_REF=UNSET
ARG BUILD_DATE=UNSET

FROM alpine:${ALPINE_VERSION} AS validation
RUN if [ "$VCS_REF" = "UNSET" ]; then \
        echo "ERROR: VCS_REF build argument is required" >&2 && \
        exit 1; \
    fi
```

### Base Image Selection
- **Alpine vs Scratch**: Use Alpine for debugging capabilities, Scratch for minimal size
- **Current Choice**: Alpine base provides shell access for troubleshooting
- **Runtime Metadata**: Files generated at build time: `.vcs-ref`, `.build-date`, `.app-version`

### LABEL Instructions
- **Final Image Only**: LABELs belong on the published artifact, not intermediate build stages
- **Comprehensive Metadata**: Include source, version, revision, title, description, created, authors
- **ARG Redeclaration**: Always redeclare ARGs in final stage before using in LABEL instructions

### Example Structure
```dockerfile
# Global ARGs - All build parameters visible at top
ARG GO_VERSION=1.25.1
ARG ALPINE_VERSION=3.19
ARG CGO_ENABLED=0
ARG GOOS=linux
ARG GOARCH=amd64
ARG LDFLAGS="-s -w"
ARG APP_VERSION=dev
ARG VCS_REF=unspecified
ARG BUILD_DATE=1970-01-01T00:00:00Z

FROM golang:${GO_VERSION} AS builder
WORKDIR /src                    # Source code location
# Clean intermediate stage - no LABELs, minimal ARGs

FROM alpine:${ALPINE_VERSION}
WORKDIR /app                    # Runtime application location
# Stage ARGs required for LABEL instructions
ARG APP_VERSION=dev
ARG VCS_REF=unspecified
ARG BUILD_DATE=1970-01-01T00:00:00Z

# All metadata LABELs on final published image
LABEL org.opencontainers.image.source="https://github.com/justincranford/cryptoutil"
LABEL org.opencontainers.image.version="${APP_VERSION}"
LABEL org.opencontainers.image.revision="${VCS_REF}"
LABEL org.opencontainers.image.title="cryptoutil"
LABEL org.opencontainers.image.description="A small utility for cryptographic key and certificate operations"
LABEL org.opencontainers.image.created="${BUILD_DATE}"
LABEL org.opencontainers.image.authors="Justin Cranford <justin@example.com>"
```

## Docker Secrets Best Practices

### CRITICAL: Shared Secrets for Cryptographic Interoperability
- **ALL cryptoutil instances MUST use the SAME unseal secrets** to enable shared encryption/decryption of data in the database
- **NEVER create instance-specific secrets** as this breaks cryptographic interoperability between services
- **REASON**: Each cryptoutil instance needs to access the same encrypted data (keys, certificates, etc.) stored in the shared database
- **PATTERN**: All services reference the same secret files in their `secrets:` configuration
- **CONSEQUENCE**: Using different secrets per instance causes "failed to find key with key ID" errors and cryptographic isolation

### Secret Mounting Patterns
```yaml
services:
  cryptoutil-sqlite:
    secrets:
      # ALL instances use the SAME secrets for cryptographic compatibility
      - cryptoutil_unseal_1of5.secret
      - cryptoutil_unseal_2of5.secret
      - cryptoutil_unseal_3of5.secret
      - cryptoutil_unseal_4of5.secret
      - cryptoutil_unseal_5of5.secret

  cryptoutil-postgres-1:
    secrets:
      # SAME secrets as other instances - CRITICAL for shared database access
      - cryptoutil_unseal_1of5.secret
      - cryptoutil_unseal_2of5.secret
      - cryptoutil_unseal_3of5.secret
      - cryptoutil_unseal_4of5.secret
      - cryptoutil_unseal_5of5.secret

  cryptoutil-postgres-2:
    secrets:
      # SAME secrets as other instances - NEVER use postgres2-specific secrets
      - cryptoutil_unseal_1of5.secret
      - cryptoutil_unseal_2of5.secret
      - cryptoutil_unseal_3of5.secret
      - cryptoutil_unseal_4of5.secret
      - cryptoutil_unseal_5of5.secret
```

### Environment Variable Anti-Patterns to Avoid
❌ **NEVER DO THIS**: Using environment variables to specify secret file paths
```yaml
environment:
  - DATABASE_URL_FILE=/run/secrets/db.secret
command: ["app", "start"]
```

✅ **ALWAYS DO THIS**: Use secrets directly with file:// URLs
```yaml
secrets:
  - database_url_secret
command: ["app", "--database-url=file:///run/secrets/database_url_secret"]
```

## Networking Considerations

### IPv4 vs IPv6 Loopback Addresses
- **CRITICAL**: `localhost` resolves differently in containers vs host systems
- **Alpine Linux**: `localhost` → `::1` (IPv6 loopback), NOT `127.0.0.1` (IPv4 loopback)
- **Connection Failures**: If your application only listens on IPv4 (`127.0.0.1`), health checks using `localhost` will fail
- **Health Check Fix**: Use explicit IP addresses (`127.0.0.1` or `::1`) instead of `localhost` in health checks
- **Verification**: Check with `getent hosts localhost` in containers to see actual resolution

### Health Check Best Practices
- **Explicit IPs**: Prefer `127.0.0.1` over `localhost` for IPv4-only services
- **Available Tools**: Use `wget` instead of `curl` (curl may not be installed in Alpine containers)
- **Certificate Handling**: Use `--no-check-certificate` for self-signed certificates in development
- **Example**: `wget --no-check-certificate -q -O /dev/null https://127.0.0.1:9090/health`

## Docker Container Guidelines

### Loopback Addresses
- **ALWAYS use 127.0.0.1 for loopback inside all Docker containers**
- **NEVER use ::1 (IPv6 loopback) or localhost for loopback inside containers**
- Use `127.0.0.1` for health checks, internal service communication, and localhost connections

### Sidecar Health Checks for Minimal Containers

**WHEN containers cannot perform internal health checks** (e.g., otel-collector-contrib), use a sidecar container for external health monitoring:

#### Recommended Approach: Alpine Sidecar with wget
```yaml
services:
  minimal-service:
    image: otel/opentelemetry-collector-contrib:latest
    # ... service configuration ...
    ports:
      - "13133:13133"  # Health check port

  minimal-service-health-check:
    image: alpine:latest  # Minimal image with wget preinstalled via busybox
    command: ["wget", "--quiet", "--tries=1", "--spider", "http://minimal-service:13133/"]
    networks:
      - app-network
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    depends_on:
      minimal-service:
        condition: service_started  # Wait for service to start, then check health

  dependent-service:
    # ... other service configuration ...
    depends_on:
      minimal-service-health-check:
        condition: service_completed_successfully  # Wait for health check to pass
```

#### Alternative: BusyBox Sidecar
```yaml
  minimal-service-health-check:
    image: busybox:latest  # Even more minimal, includes wget
    command: ["wget", "--quiet", "--tries=1", "--spider", "http://minimal-service:13133/"]
    # ... same configuration as Alpine example ...
```

#### Key Benefits
- **Minimal footprint**: Alpine/BusyBox images are very small (< 10MB)
- **Preinstalled tools**: wget comes with busybox (Alpine/BusyBox base)
- **External monitoring**: Checks service health from network perspective
- **Dependency management**: Use `service_completed_successfully` for clean startup ordering
- **Retry logic**: Built-in restart policy handles temporary failures

#### When to Use Sidecar Health Checks
- Containers lacking shell or standard utilities (curl, wget, etc.)
- Minimal images with only application binaries
- Services that cannot health-check themselves internally
- Need for external validation of service readiness

### otel-collector-contrib Container Limitations
- **NO shell available**: Cannot execute shell commands or scripts
- **NO standard utilities**: Missing commands: `which`, `curl`, `ls`, `wget`, `bash`, `sh`, `find`, `grep`, `cat`, etc.
- **Limited debugging**: Cannot use common container inspection commands
- **Health checks**: Must use external health checking (from host) since curl/wget unavailable
- **Available tools**: Only OTEL collector binary (`/otelcol-contrib`) and basic system tools
- **Executable limitations**: `/otelcol-contrib` does not support running as a client to health check its own in-memory server process
- **External health checks**: When containers don't support internal memory checks, use docker compose.yml `healthcheck` directive for external monitoring
- **Container contents**: Minimal Alpine-based image with only `/otelcontribcol` binary and `/etc/ssl/certs/ca-certificates.crt`
- **No internal health check files**: No log files, status files, or other mechanisms for internal health validation

## Docker Compose Service Port Reference

### cryptoutil Services (3 instances)

**cryptoutil-sqlite** (Port 8080)
- Public API (HTTPS): `https://127.0.0.1:8080`
- Browser API: `https://127.0.0.1:8080/browser/api/v1/*`
- Service API: `https://127.0.0.1:8080/service/api/v1/*`
- Swagger UI: `https://127.0.0.1:8080/ui/swagger`
- Admin API (HTTPS): `https://127.0.0.1:9090` (livez, readyz, shutdown)
- Backend: SQLite in-memory database

**cryptoutil-postgres-1** (Port 8081)
- Public API (HTTPS): `https://127.0.0.1:8081`
- Browser API: `https://127.0.0.1:8081/browser/api/v1/*`
- Service API: `https://127.0.0.1:8081/service/api/v1/*`
- Swagger UI: `https://127.0.0.1:8081/ui/swagger`
- Admin API (HTTPS): `https://127.0.0.1:9090` (livez, readyz, shutdown)
- Backend: PostgreSQL database (shared with postgres_2)

**cryptoutil-postgres-2** (Port 8082)
- Public API (HTTPS): `https://127.0.0.1:8082`
- Browser API: `https://127.0.0.1:8082/browser/api/v1/*`
- Service API: `https://127.0.0.1:8082/service/api/v1/*`
- Swagger UI: `https://127.0.0.1:8082/ui/swagger`
- Admin API (HTTPS): `https://127.0.0.1:9090` (livez, readyz, shutdown)
- Backend: PostgreSQL database (shared with postgres_1)

## cryptoutil Configuration File Requirements

### Instance-Specific Configuration Files

**CRITICAL: ALL settings in instance-specific config files MUST BE UNIQUE and CORRESPOND TO the service name in compose.yml**

Each cryptoutil service has its own configuration file with settings that must be unique to that specific service instance:

#### cryptoutil-sqlite.yml (for cryptoutil-sqlite service)
```yaml
# CRITICAL: ALL settings in this file MUST BE UNIQUE and CORRESPOND TO the 'cryptoutil-sqlite' service name in compose.yml
# Changing any values here will break cryptographic interoperability and service identification

# CORS configuration - HTTPS origins only (from default config)
cors-origins:
  - "https://localhost:8080"
  - "https://127.0.0.1:8080"
  - "https://[::1]:8080"
  - "https://[::ffff:127.0.0.1]:8080"

otlp-service: cryptoutil-sqlite
otlp-hostname: cryptoutil-sqlite

# Development mode - enables in-memory SQLite
dev: true
```

#### cryptoutil-postgresql-1.yml (for cryptoutil-postgres-1 service)
```yaml
# CRITICAL: ALL settings in this file MUST BE UNIQUE and CORRESPOND TO the 'cryptoutil-postgres-1' service name in compose.yml
# Changing any values here will break cryptographic interoperability and service identification

# CORS configuration - HTTPS origins only (from default config)
cors-origins:
  - "https://localhost:8081"
  - "https://127.0.0.1:8081"
  - "https://[::1]:8081"
  - "https://[::ffff:127.0.0.1]:8081"

otlp-service: cryptoutil-postgresql-1
otlp-hostname: cryptoutil-postgresql-1
```

#### cryptoutil-postgresql-2.yml (for cryptoutil-postgres-2 service)
```yaml
# CRITICAL: ALL settings in this file MUST BE UNIQUE and CORRESPOND TO the 'cryptoutil-postgres-2' service name in compose.yml
# Changing any values here will break cryptographic interoperability and service identification

# CORS configuration - HTTPS origins only (from default config)
cors-origins:
  - "https://localhost:8082"
  - "https://127.0.0.1:8082"
  - "https://[::1]:8082"
  - "https://[::ffff:127.0.0.1]:8082"

otlp-service: cryptoutil-postgresql-2
otlp-hostname: cryptoutil-postgresql-2
```

**Key Requirements for Instance-Specific Files:**
- **Service Name Correspondence**: Comments must reference the EXACT service name from compose.yml
- **Unique Settings**: ALL settings must be unique per instance (ports, service names, hostnames, CORS origins)
- **No Shared Values**: Never duplicate settings between instance files
- **CORS Origins**: Must match the exposed ports for each service
- **OTLP Service/Hostname**: Must be unique and match the service identity

### Common Configuration File

#### cryptoutil-common.yml (shared by ALL cryptoutil services)
```yaml
# CRITICAL: This file contains COMMON settings used by ALL cryptoutil services in compose.yml
# ALL cryptoutil instances (cryptoutil-sqlite, cryptoutil-postgres-1, cryptoutil-postgres-2)
# MUST use this file for shared configuration. Instance-specific settings belong in
# their respective config files (cryptoutil-sqlite.yml, cryptoutil-postgresql-1.yml, cryptoutil-postgresql-2.yml)
# Changing settings here affects ALL cryptoutil services.

# Logging level (ALL, TRACE, DEBUG, CONFIG, INFO, NOTICE, WARN, ERROR, FATAL, OFF)
# log-level: "INFO"

# Binding address - 0.0.0.0 allows connections from any NIC within the container
bind-public-address: "0.0.0.0"

# TLS configuration for HTTPS
tls-cert-file: /app/tls_public_server_certificate_0.pem
tls-key-file: /app/tls_public_server_private_key.pem

unseal-mode: "3-of-5"

unseal-files:
  - /run/secrets/cryptoutil_unseal_1of5.secret
  - /run/secrets/cryptoutil_unseal_2of5.secret
  - /run/secrets/cryptoutil_unseal_3of5.secret
  - /run/secrets/cryptoutil_unseal_4of5.secret
  - /run/secrets/cryptoutil_unseal_5of5.secret

# Allow all IPs for development/testing
allowed-ips:
  - "127.0.0.1"
  - "::1"
  - "::ffff:127.0.0.1"
allowed-cidrs:
  - "0.0.0.0/0"
  - "::/0"

# Disable CSRF for API testing
csrf-token-single-use-token: false
```

**Key Requirements for Common File:**
- **Shared Settings**: Contains settings used by ALL cryptoutil instances
- **Cryptographic Configuration**: Unseal settings, TLS config, security policies
- **No Instance-Specific Values**: Never include service-specific settings
- **Critical for Interoperability**: Settings here ensure all instances can access shared encrypted data

### PostgreSQL Database

**postgres** (Port 5432)
- Host: `localhost:5432` (or `postgres:5432` from containers)
- Database: `DB`
- User: `USR`
- Password: `PWD`
- Health Check: `pg_isready -U USR -d DB`

### OpenTelemetry Collector

**opentelemetry-collector-contrib** (Multiple Ports)
- OTLP gRPC: `http://127.0.0.1:4317` (receive application telemetry)
- OTLP HTTP: `http://127.0.0.1:4318` (receive application telemetry)
- Self-metrics (Prometheus): `http://127.0.0.1:8888/metrics` (collector internal metrics)
- Received-metrics (Prometheus): `http://127.0.0.1:8889/metrics` (re-export received metrics)
- Health Check: `http://127.0.0.1:13133/` (external health monitoring)
- pprof: `http://127.0.0.1:1777` (performance profiling)
- zPages: `http://127.0.0.1:55679` (debugging UI)
- Health Monitoring: Via `healthcheck-opentelemetry-collector-contrib` sidecar (Alpine with wget)

**healthcheck-opentelemetry-collector-contrib** (Sidecar)
- Purpose: External health validation for OTEL collector
- Implementation: Alpine container with ping + wget validation
- Exit Code: 0 = healthy, non-zero = unhealthy
- Dependency: Other services wait for `service_completed_successfully`

### Grafana Observability Stack

**grafana-otel-lgtm** (Port 3000)
- Grafana UI: `http://127.0.0.1:3000` (admin/admin)
- OTLP gRPC Receiver: `http://127.0.0.1:14317` (receive from OTEL collector)
- OTLP HTTP Receiver: `http://127.0.0.1:14318` (receive from OTEL collector)
- Health Check: `curl http://localhost:3000/api/health`
- Includes: Grafana, Loki (logs), Tempo (traces), Prometheus (metrics)

### Telemetry Data Flow

```
cryptoutil services → OTEL Collector (4317/4318 OTLP) → Grafana LGTM (14317/14318 OTLP)
                      OTEL Collector self-metrics (8888) → Prometheus scraping
```

### Common Connection Patterns

**From Host (Development/Testing):**
- cryptoutil APIs: `https://127.0.0.1:8080-8082`
- PostgreSQL: `localhost:5432`
- OTEL Collector: `http://127.0.0.1:4317-4318`
- Grafana UI: `http://127.0.0.1:3000`

**From Containers (Docker Network):**
- cryptoutil APIs: `https://cryptoutil-sqlite:8080` (or postgres_1:8081, postgres_2:8082)
- PostgreSQL: `postgres:5432`
- OTEL Collector: `http://opentelemetry-collector-contrib:4317-4318`
- Grafana: `http://grafana-otel-lgtm:3000`

**Admin APIs (Internal Only):**
- All cryptoutil instances expose admin endpoints on HTTPS port 9090 (not mapped to host)
- Access via: `docker compose exec cryptoutil-sqlite wget --no-check-certificate -q -O - https://127.0.0.1:9090/livez`
