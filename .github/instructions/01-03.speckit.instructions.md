---
description: "Instructions for Speckit methodology workflow integration, evidence requirements, and feedback loops"
applyTo: "**"
---
# Speckit Workflow Integration - CRITICAL

SpecKit (Specification Kit) is a spec-driven development (SDD) design and validation toolset. It allows LLM Agents to implement designs autonomously.

There are seven steps. Two are optional, but highly recommended: 1. constitution, 2. clarify (optional), 3. spec, 4. plan, 5. tasks, 6. analyze (optional), 7. implement

SpecKit shines when you want to Design before Implementing code. It catches design issues early. Workflows is a straight line or spiral, which helps direct LLM Agents to converge on a working implementation that satisfies design requirements.

SpecKit is not good for Human SDLC, due to lack of iterative feedback loops. It is also not good at validating implementation, business domain rules, or complex state transitions. Don't use it for spiking or iterating quickly, because it can feel heavy, slow, and overly restrictive.

## Customizations

**Living Documents**: Treat constitution, spec, and plan as evolving through implementation feedback - not static prerequisites. Update immediately when discovering constraints, contradictions, or insights.

**Treat Clarify and Analyze steps as MANDATORY**: These are optional, but highly recommended. Clarify helps identify and fix issues in constitution and spec, before proceeding to plan.

**Produce CLARIFY-QUIZME-##.md during Clarify step**: It pays to spend extra time in the Clarify step, to identify and fix as many issues as possible in constitution and spec, before proceeding to plan.

**MANDATORY**: CLARIFY-QUIZME-##.md MUST only contain UNKNOWN answers requiring user input. For efficiency, the format MUST be multiple choice questions, with insightful A-D answers, and a blank E write-in answer.

**NEVER include**:

- ❌ Questions with answers from codebase/constitution/spec/copilot instructions
- ❌ Pre-filled answers or example answers in Write-in questions

**ALWAYS**:

- ✅ Search codebase/docs before adding questions to CLARIFY-QUIZME-##.md
- ✅ Merge CLARIFY-QUIZME-##.md answers into clarify.md, refactor structure and content to accommodate, if necessary
- ✅ Use updated clarify.md to backport clarifications into constitution.md and spec.md
- ✅ Re-analyze constitution.md, spec.md, and clarify.md, and generate another CLARIFY-QUIZME-##.md automatically
- ✅ Prompt the user to review the CLARIFY-QUIZME-##.md, if it contains any new questions, or automatically run /specify.plan and notify the user

## Workflow Gates - MANDATORY

| Gate | Evidence Required | Validation |
|------|-------------------|------------|
| **Constitution** | No TBD placeholders, terminology defined, quality gates, alignment with copilot instructions without any conflicts | `grep -i "TBD\|TODO\|FIXME" constitution.md` = 0 |
| **Specification** | Functional/non-functional requirements, architecture, API contracts, services overview, databases overview, security requirements | Verify all constitution requirements mapped |
| **Clarification** | Topical organization, clarify.md for knowns, CLARIFY-QUIZME-##.md for unknowns | Verify no pending questions |
| **Plan** | Phases with tasks breakdowns, task dependencies, completion criteria per phase, risk assessment, aligns with constitution/spec/copilot | Compare plan vs constitution/spec/clarify |
| **Tasks** | Task checklist, completion criteria per task, phase assignments, dependencies, effort estimates (S/M/L) | Verify tasks.md matches plan.md phases |
| **Analysis** | Complexity analysis, risk assessment, dependency graph, resource requirements (optional) | Verify analyze.md exists if needed |
| **Implementation** | Track in DETAILED.md Sections 1+2, EXECUTIVE.md, issues found, risks discovered, lessons learned, progress evidence (i.e. tests pass, coverage ≥95%/98%, mutation ≥85%/98%, timing <15s/<120s unit, <45s/<240s E2E) | `go test ./... -coverprofile`, `gremlins unleash` |

## Evidence-Based Completion during Implementation - MANDATORY

**NEVER mark tasks complete during Implementation without objective evidence**:

- Code: `go build ./...` clean, `golangci-lint run` clean, no new TODOs, coverage ≥95%/98%
- Tests: `go test ./...` passes, no skips without tracking
- Mutations: `gremlins unleash` passes, quality analysis shows ≥85% during early phases, and quality gate jumps to ≥98% during later phases
- Git: Conventional commit, clean tree, changes align with task
- Git Hooks: pre-commit checks pass, pre-push checks pass

## Feedback Loop Patterns during Implementation - MANDATORY

**When discovering constraints/contradictions/lessons**:

1. Document in DETAILED.md Section 2 timeline, and mark it as needing user review to putting in copilot anti-patterns` instructions
2. Document in EXECUTIVE.md, and mark it as needing user review to putting in copilot anti-patterns` instructions
3. Update constitution/spec/clarify immediately
4. Commit with traceable reference to source

**CRITICAL: DON'T PROMPT THE USER TO REVIEW DETAILED.md and EXECUTIVE.md. THE USER ALREADY IMPLICITLY KNOWS TO ASYNCHRONOUSLY REVIEW DETAILED.md and EXECUTIVE.md.**

## DETAILED.md Structure

**Section 1: Task Checklist** - Maintain from tasks.md with ❌/⚠️/✅ status, blockers, notes, coverage, commits

**Section 2: Append-Only Timeline** - Chronological entries with:

- Date: Task description
- Work completed
- Coverage/quality metrics
- Lessons learned
- Constraints discovered (add to constitution.md)
- Requirements discovered (add to spec.md)
- Related commits

## EXECUTIVE.md Structure

**Stakeholder Overview**: Current phase, progress %, coverage, mutation score, blockers

**Customer Demonstrability**: Docker Compose commands, E2E demo scenarios

**Risk Tracking**: Known issues with severity, impact, workaround, root cause, resolution, status

**Post-Mortem Lessons**: Lesson learned, prevention pattern, where applied, reference docs
