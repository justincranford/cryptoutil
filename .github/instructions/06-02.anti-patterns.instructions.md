---
description: "Common anti-patterns and mistakes to avoid based on post-mortems and session learnings"
applyTo: "**"
---
# Anti Patterns

## CRITICAL Regression-Prone Areas

### Format_go Self-Modification - P0 INCIDENTS

**Root Cause**: LLM agents lose exclusion context during narrow-focus refactoring, inadvertently modifying self-exclusion patterns.

#### MANDATORY Prevention Rules

**NEVER DO**:

- ❌ Modify comments or test data in `enforce_any.go` without reading full package context
- ❌ Change `` `interface{}` `` to `` `any` `` in format_go package without verification
- ❌ Refactor code in isolation (single-file view)
- ❌ Simplify "verbose" CRITICAL comments without understanding purpose

**ALWAYS DO**:

- ✅ Read complete package context before refactoring self-modifying code
- ✅ Check for CRITICAL/SELF-MODIFICATION tags in comments
- ✅ Verify self-exclusion patterns exist and are respected
- ✅ Run tests after ANY changes to format_go package
- ✅ Grep for exclusion constants in `magic_cicd.go`

#### Pattern Recognition

**Indicators of Intentional Protection**:

- **CRITICAL comments**: High-priority annotations requiring preservation
- **Backticked strings** in code: `` `interface{}` `` → Prevents replacement by pattern matching
- **Test data patterns**: May use "wrong" values intentionally (e.g., `interface{}` as input to test replacement)
- **Self-exclusion constants**: `MagicCICDFilterExcludeEnforceAny` in `magic_cicd.go`

#### Code Archaeology Checklist

**Required Reading**: enforce_any.go, filter.go, magic_cicd.go, format_go_test.go, self_modification_test.go, docs/P0.*, git log

---

### Windows Firewall Exception Prevention - CRITICAL

**Problem**: Binding to `0.0.0.0` triggers Windows Firewall prompts in tests.

**Rules**:

- ❌ NEVER bind to `0.0.0.0` in tests (triggers firewall)
- ❌ NEVER use `localhost` (ambiguous IPv4/IPv6)
- ✅ ALWAYS use `127.0.0.1` or `cryptoutilMagic.IPv4Loopback` in tests
- ✅ Use `0.0.0.0` ONLY in Docker containers

**Detection**: `grep -r "0.0.0.0" **/*_test.go`

---

### SQLite Connection Pool Deadlocks - P0 INCIDENT

**Problem**: GORM transactions require multiple connections, `MaxOpenConns=1` causes deadlock.

**Rules**:

- ❌ NEVER set `MaxOpenConns=1` with GORM transactions
- ❌ NEVER use `sql.TxOptions{ReadOnly: true}` with SQLite (not supported)
- ✅ ALWAYS set `MaxOpenConns=5` (`cryptoutilMagic.SQLiteMaxOpenConnections`)
- ✅ ALWAYS enable WAL mode
- ✅ ALWAYS set busy timeout 30s (`cryptoutilMagic.DBSQLiteBusyTimeout`)

**Reference**: `internal/server/repository/sqlrepository/sql_provider.go` lines 201-213

---

### Docker Compose Port Conflicts - E2E FAILURES

**Problem**: Multiple services including same telemetry compose file cause host port conflicts.

**Rules**:

- ❌ NEVER expose container ports to host if multiple instances may run
- ✅ ALWAYS use container-to-container networking (no host port mappings)
- ✅ Services communicate via container names (e.g., `opentelemetry-collector-contrib:4317`)

**Detection**: "bind: address already in use" or "port is already allocated"

**Diagnosis**:

```bash
# Check what's using the port
netstat -ano | findstr "4317"  # Windows
lsof -i :4317                  # Linux/Mac

# Check included compose files
grep -r "ports:" deployments/*/compose.yml
```

**Fix**:

1. Remove host port mappings from shared compose files
2. Use container-to-container networking only
3. Update application configs to use container names
4. Test all E2E workflows in sequence to verify no conflicts

---

### Incomplete Service Implementation - WORKFLOW DEBUGGING

**Problem**: Missing public HTTP servers cause cascading configuration errors that mask root cause.

#### Root Cause

**Assumption Bias**: Assumed container crashes were ALWAYS configuration problems, not missing code.

#### Symptom Pattern

**Progressive Configuration Fixes with Zero Symptom Change**:

- Decreasing log bytes = earlier crash = deeper problem (NOT configuration)
- Same bytes despite valid fixes = implementation issue, NOT configuration

#### NEVER DO

❌ **Keep applying configuration fixes when symptoms don't change**
❌ **Assume container crash is always a configuration problem**
❌ **Debug configuration before verifying complete architecture exists**

#### ALWAYS DO

✅ **Code archaeology FIRST - compare with working service before debugging config**
✅ **Verify all required files exist** (server.go, application.go, admin.go)
✅ **Check Application.Start() initializes both public + admin servers**
✅ **Compare container log byte counts across fix attempts**

#### Detection Pattern

**Indicators of Missing Implementation**:

1. **Byte count pattern**: Same bytes across multiple fix rounds = no symptom change
2. **Error message pattern**: Early rounds show specific errors, later rounds show generic startup then silence
3. **File structure pattern**: Compare with working service - notice missing files

#### Time Wasted Pattern

- Configuration Debugging: 40-60 minutes (4-6 rounds × 10 minutes each)
- Code Archaeology Upfront: 9 minutes (download logs + compare architecture)

**Lesson**: Code archaeology should be FIRST step, NOT last resort

---

## Testing Anti-Patterns

### Coverage Improvement Without Baseline Analysis

**Problem**: Writing 60+ tests without analyzing baseline coverage HTML = 0% improvement.

**Symptom**: Massive test file (1000+ lines), coverage unchanged

#### NEVER DO

❌ **Write tests without checking baseline coverage first**
❌ **Add tests randomly hoping to hit uncovered code**
❌ **Trial-and-error test writing cycles**

#### ALWAYS DO

✅ **Generate baseline coverage**: `go test ./pkg -coverprofile=./test-output/coverage_pkg.out`
✅ **Analyze HTML to identify RED (uncovered) lines**: `go tool cover -html=...`
✅ **Identify specific functions with coverage gaps**: `go tool cover -func=... | grep "0.0%"`
✅ **Write targeted tests for identified gaps**
✅ **Verify improvement with new coverage report**

#### Lesson

**Coverage ≠ Test Count**: Many tests can add 0% if exercising already-covered code paths.

**Efficient Pattern**: Baseline → Analyze RED lines → Targeted tests → Verify

---

### Individual Test Functions vs Table-Driven

**Problem**: Creating `TestFunc_Variant1`, `TestFunc_Variant2`, `TestFunc_Variant3` as separate functions.

**Result**: 1371-line test file (2.7× hard limit of 500 lines), maintenance nightmare, slower LLM processing

#### NEVER DO

❌ **Separate test functions for algorithm/key size variants**
❌ **Duplicate setup code across multiple test functions**

#### ALWAYS DO

✅ **Use table-driven tests with variants as rows**
✅ **Group related test cases in single function with `t.Run(tt.name, ...)`**
✅ **Keep test files under 500 lines (hard limit)**

#### File Size Limits

| Limit | Lines | Action Required |
|-------|-------|-----------------|
| Soft | 300 | Ideal target |
| Medium | 400 | Acceptable with justification |
| Hard | 500 | NEVER EXCEED - refactor required |

---

### Race Condition Testing Patterns

**Problem**: Race detector overhead (~10×) causes test timeouts with short deadlines.

**Symptom**: Tests pass normally, fail with `context deadline exceeded` under `-race`

#### NEVER DO

❌ **Hardcode 2-second timeouts for network operations**
❌ **Assume race detector runs at normal speed**

#### ALWAYS DO

✅ **Use 10+ second timeouts for network operations in race mode**
✅ **Increase test timeouts 10× when race detector enabled**
✅ **Add thread-safe accessor methods (RLock/RUnlock) for shared state**
✅ **Never access shared maps/slices without mutex protection**

#### Pattern

`context deadline exceeded` errors under `-race` = insufficient timeout, NOT actual bug

**Fix**: Increase timeout 10× or use dynamic timeout based on race detector flag

---

## Git Workflow Anti-Patterns

### Amending Repeatedly (Loses History)

**Problem**: Using `git commit --amend` repeatedly loses history, masks mistakes, breaks bisect.

**Symptom**: Commit history shows 1 commit with 50 changes, impossible to identify when specific bug introduced

#### NEVER DO

❌ **Amend commit after push (breaks shared history)**
❌ **Amend repeatedly during debugging session**
❌ **Use amend to hide incremental fixes**

#### ALWAYS DO

✅ **Commit each logical unit independently**
✅ **Preserve full timeline of changes and decisions**
✅ **Enable git bisect to identify when bugs were introduced**
✅ **Use amend ONLY for immediate typo fixes (within 1 minute, before push)**

#### Rationale

**Incremental Commits**:

- Preserve context (why each change was made)
- Enable selective revert (revert specific fix without losing others)
- Show thought process (debugging steps visible)
- Support bisect (identify exact commit that introduced bug)

---

### Applying Fixes to Corrupted HEAD

**Problem**: Assuming HEAD is correct when it may be corrupted from previous failed attempts.

**Symptom**: Apply "one more fix" on top of corrupted code → fails again → more fixes → fails again (cycle)

#### NEVER DO

❌ **Apply "one more fix" on top of corrupted code**
❌ **Mix baseline restoration with new fixes in same commit**
❌ **Assume HEAD is always clean**

#### ALWAYS DO

✅ **Restore clean baseline from known-good commit FIRST**
✅ **Verify baseline works (tests pass)**
✅ **Apply ONLY the new fix (minimal change)**
✅ **Commit as NEW commit with clear description**

#### Pattern

**Find Last Known-Good** → **Restore Baseline** → **Verify Baseline** → **Apply Targeted Fix** → **Verify Fix** → **Commit Separately**

**Why**: HEAD corruption accumulates from failed attempts. Start fresh from verified clean state.

---

## Documentation Anti-Patterns

### Creating Standalone Session Documentation

**Problem**: Creating dated session documentation files leads to documentation bloat.

**Result**: 50+ session docs scattered across `docs/`, difficult to find historical context

#### NEVER DO

❌ **Create dated session documentation files** (docs/SESSION-*.md)
❌ **Create standalone analysis documents for session work**
❌ **Create separate work log files per session**

#### ALWAYS DO

✅ **Append to `specs/*/implement/DETAILED.md` Section 2 timeline**
✅ **Single source of truth for implementation timeline**
✅ **Create separate docs ONLY for permanent reference material** (ADRs, post-mortems, user guides)

#### Rule of Thumb

**Session-specific work** → Append to `DETAILED.md`

**Permanent reference** → Create dedicated doc:

- `docs/ADR-001-database-choice.md` (architectural decision)
- `docs/P0.1-format-go-regression.md` (post-mortem)
- `docs/USER-GUIDE.md` (user documentation)

---

## Architecture Anti-Patterns

### Missing Service Federation Configuration

**Problem**: Services don't know how to discover or communicate with federated services.

**Symptom**: Hardcoded service URLs in code, fails when service moves (e.g., cipher-im service in different namespace)

#### NEVER DO

❌ **Hardcode service URLs in application code**
❌ **Assume services are always co-located**

#### ALWAYS DO

✅ **Use configuration for service discovery** (YAML, environment, DNS)
✅ **Support multiple federation patterns** (DNS-based discovery, Config file URLs, Service mesh integration)
✅ **Implement graceful degradation when federated services unavailable**

#### Pattern

**Service A depends on Service B** → Configure B's URL in A's config, NOT hardcode

---

## Performance Anti-Patterns

### Mutation Testing Timeout (>45 minutes)

**Problem**: Running gremlins on entire codebase sequentially causes 45-minute timeouts.

**Symptom**: CI workflow exceeds job timeout, incomplete mutation coverage

#### NEVER DO

❌ **Run mutation testing on all packages sequentially**
❌ **Include test utilities and generated code in mutation scope**

#### ALWAYS DO

✅ **Parallelize by package using GitHub Actions matrix strategy**
✅ **Exclude tests, generated code, vendor directories**
✅ **Set per-job timeout (15 minutes max)**
✅ **Target <20 minutes total with parallel execution**

#### Optimization

**4-6 packages per parallel job**, focus on business logic only

**Expected Result**: Sequential 45 minutes → Parallel 15-20 minutes (2-3× speedup)

---

### Test Timing Violations (>15s per package)

**Problem**: Test packages taking >15 seconds due to exhaustive algorithm variant testing.

**Symptom**: `go test ./...` takes >180 seconds (violates target)

#### NEVER DO

❌ **Test every key size variant (RSA 2048/3072/4096) every time**
❌ **Use `TestProbAlways` for redundant variants**

#### ALWAYS DO

✅ **Use `TestProbTenth` (10%) or `TestProbQuarter` (25%) for algorithm variants**
✅ **Reserve `TestProbAlways` (100%) for base algorithms only**
✅ **Target <15s per unit test package, <180s full unit test suite**

#### Rationale

**Statistical Sampling**: Bugs eventually caught without running all variants every time

**Magic Constants**:

- `TestProbAlways = 100` (100%) - Base algorithms
- `TestProbQuarter = 25` (25%) - Important variants
- `TestProbTenth = 10` (10%) - Redundant variants

---

## Key Takeaways

### Context Reading - CRITICAL

**ALWAYS read complete context before refactoring self-modifying code**. Check for CRITICAL tags, self-exclusion patterns, test validation patterns.

### Windows Firewall - CRITICAL

**ALWAYS bind to 127.0.0.1 in tests** (NEVER 0.0.0.0). Use 0.0.0.0 ONLY in Docker containers (isolated namespace).

### Coverage Analysis - MANDATORY

**ALWAYS analyze baseline HTML before writing tests**. Identify RED lines, write targeted tests, verify improvement.

### Incremental Commits - BEST PRACTICE

**NEVER amend repeatedly** - preserve history for bisect. Commit each logical unit independently.

### Restore from Clean - BEST PRACTICE

**ALWAYS restore clean baseline before applying fixes**. HEAD may be corrupted from previous attempts.

### Port Conflicts - CRITICAL

**Remove host port mappings for shared services in Docker Compose**. Use container-to-container networking only.

### Mutation Parallelization - PERFORMANCE

**NEVER run sequentially** - use GitHub Actions matrix. 4-6 packages per job, <20 minutes total.

### Test Timeouts - COMPATIBILITY

**ALWAYS increase timeouts 10× for race detector mode**. Race detector overhead ~10× normal execution.

---

## Cross-References

**Related Documentation**: coding.md (format_go protection patterns), security.md (Windows Firewall prevention), sqlite-gorm.md (SQLite configuration), docker.md (Docker Compose patterns), testing.md (testing standards), git.md (git workflow), docs/WORKFLOW-FIXES-CONSOLIDATED.md (workflow debugging), docs/P0.* files (post-mortems)
