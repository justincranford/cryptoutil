---
description: "Instructions for CI/CD workflow configuration and service connectivity verification"
applyTo: ".github/workflows/*.yml"
---
# CI/CD Workflow Instructions

## CI/CD Cost Efficiency

**Optimize workflow execution to minimize GitHub Actions billed minutes:**

- **Trigger optimization**: Only run workflows on relevant file changes (use path filters)
- **Matrix builds**: Keep job matrices minimal, avoid unnecessary combinations
- **Dependency caching**: Use Go module caching to reduce build times
- **Skip trivial changes**: Use conditionals to skip jobs for docs-only or trivial changes
- **Job filters**: Apply conditionals to avoid wasteful runs (e.g., skip deployment on forks)

## Workflow Architecture Overview

The CI/CD pipeline consists of 6 specialized workflows with different service orchestration approaches:

| Workflow | File | Services | Connectivity Verification | Primary Purpose |
|----------|------|----------|---------------------------|-----------------|
| Quality | `ci-quality.yml` | None | N/A | Code quality, linting, formatting, builds |
| SAST | `ci-sast.yml` | None | N/A | Static security analysis |
| Robustness | `ci-robust.yml` | None | N/A | Concurrency, fuzz, benchmarks |
| DAST | `ci-dast.yml` | Standalone app | Bash/curl | Dynamic security scanning |
| E2E | `ci-e2e.yml` | Full Docker stack | Go test infra | Integration testing |
| Load | `ci-load.yml` | Full Docker stack | Bash/curl | Performance testing |

## Service Connectivity Verification Patterns

### Pattern 1: No Service Connectivity Verification

**When to Use**: Workflows that perform static analysis, unit tests, or builds without starting services

**Workflows**: `ci-quality.yml`, `ci-sast.yml`, `ci-robust.yml`

---

### Pattern 2: Go-Based E2E Infrastructure

**When to Use**: Workflows that require comprehensive integration testing with full Docker Compose orchestration

**Workflow**: `ci-e2e.yml`

**Key Components**:
```go
// internal/test/e2e/infrastructure.go
- Docker Compose orchestration (start/stop services)
- Multi-stage health checking (Docker health + HTTP connectivity)
- Exponential backoff retry logic

// internal/test/e2e/docker_health.go  
- Parse `docker compose ps --format json` output
- Handle 3 service types: jobs, service with internal healthcheck, service with external healthcheck job
- Complex, comprehensive health status determination

// internal/test/e2e/http_utils.go
- CreateInsecureHTTPClient() with InsecureSkipVerify for self-signed certs
- HTTP GET requests with context for timeouts
```

**Why Go Infrastructure**:
- Cross-platform (Windows dev, Linux CI runners, macOS dev)
- Complex, comprehensive error handling
- Better debugging with stack traces

---

### Pattern 3: Non-Go API Tests (DAST, Load)

**When to Use**: Workflows that need simple service readiness check (ZAP, Nuclei, Gatling)

**Workflows**: `ci-dast.yml`, `ci-load.yml`

# Check HTTPS endpoints (cryptoutil uses self-signed certs in CI)
```
check_endpoint "https://127.0.0.1:8080/ui/swagger/doc.json" "cryptoutil-sqlite"
check_endpoint "https://127.0.0.1:8081/ui/swagger/doc.json" "cryptoutil-postgres-1"
check_endpoint "https://127.0.0.1:8082/ui/swagger/doc.json" "cryptoutil-postgres-2"
```

## Configuration Management

### Application Configuration (Production/CI Deployments)
- **ALWAYS use config files** for production and CI application deployments
- **Example**: `cryptoutil server start --config configs/production/config.yml`
- **Database**: Config files should specify actual database connections (PostgreSQL for production)
- **CI/CD Pattern**: Copy and modify base config files for different environments rather than using environment variables
- **Why**: Config files are version-controlled, documented, and prevent environment variable naming mistakes
- **NEVER use environment variables for secrets

### Environment Variables (When Necessary)
- **Use sparingly**: Only for emergency overrides or local development when secrets infrastructure isn't available
- Check `config.go` for the exact setting names and their corresponding environment variables

### Test Configuration (Development/Testing)
- **Tests ALWAYS use SQLite in-memory databases**
- When running `cryptoutil server start --dev`, the application automatically switches to SQLite for development/testing

## Go Module Caching Best Practices

### Use `cache: true` on `setup-go` Action
- **Preferred**: `cache: true` on `actions/setup-go@v6`
- **Why**: Automatic, self-healing, prevents tar extraction conflicts
- **Avoid**: Manual `actions/cache@v4` for Go modules (brittle, requires workarounds)

### Cache Key Strategy
- Use `go.sum` hash for cache invalidation
- Include OS in key for cross-platform compatibility
- Consider dependency count for large monorepos

### Troubleshooting
- Cache misses: Check `go.sum` changes
- Cache corruption: Let `setup-go` handle it automatically
- Performance issues: Monitor cache hit rates in workflow logs

## Artifact Management Best Practices

### Actions Tab Artifacts (Downloadable)
- **ALWAYS upload artifacts to Actions tab** for any generated reports, logs, or outputs that users/developers might need to download
- Use `actions/upload-artifact@v4` with descriptive names and `if: always()` condition
- Include retention policies: `retention-days: 2` for reports, `retention-days: 1` for temporary files

### Security Tab Integration (SARIF)
- **ALWAYS upload security findings to GitHub Security tab** using `github/codeql-action/upload-sarif@v3`
- Upload SARIF files for SAST, DAST, container scanning, and dependency analysis results
- Use `if: always() && hashFiles('file.sarif') != ''` to avoid failures when no issues found
- **Dual upload pattern**: Upload both to Security tab (for visualization) AND Actions tab (for downloadability)

### Additional Best Practices
- Use consistent artifact naming conventions across workflows
- Include timestamps or run IDs in artifact names when multiple runs possible
- Compress large artifacts to reduce storage costs
- Document artifact contents in workflow comments
- Clean up temporary artifacts within workflows to avoid clutter

## Act Workflow Testing

### CRITICAL: Use cmd/workflow Utility

**ALWAYS use `go run ./cmd/workflow` for running act workflows**

```bash
# Quick DAST scan (3-5 minutes)
go run ./cmd/workflow -workflows=dast -inputs="scan_profile=quick"

# Full DAST scan (10-15 minutes)
go run ./cmd/workflow -workflows=dast -inputs="scan_profile=full"

# Multiple workflows
go run ./cmd/workflow -workflows=e2e,dast

# Available workflows: e2e, dast, sast, robust, quality, load
```

### Timing Expectations
- **Quick profile**: 3-5 minutes (Nuclei + ZAP scans)
- **Full profile**: 10-15 minutes (comprehensive scanning)
- **Deep profile**: 20-25 minutes (exhaustive scanning)

### Common Mistakes to AVOID
❌ **NEVER**: Use `-t` timeout flag or check output too early
❌ **NEVER**: `Start-Sleep -Seconds 60` (way too short)
❌ **NEVER**: `Get-Content -Wait` on log while scan runs (kills process)
❌ **NEVER**: Run act commands directly without monitoring

✅ **ALWAYS**: Use `cmd/workflow` for automated monitoring
✅ **ALWAYS**: Review generated workflow analysis markdown files
✅ **ALWAYS**: Let utility complete before checking outputs

**CI/CD Workflows (Prefer 127.0.0.1):**
```bash
curl -skf https://127.0.0.1:8080/ui/swagger/doc.json
```
