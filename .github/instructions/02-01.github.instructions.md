---
description: "Instructions for CI/CD workflow configuration, service connectivity verification, and diagnostic logging"
applyTo: ".github/workflows/*.yml"
---
# CI/CD Workflow Instructions

## CI/CD Cost Efficiency

**Optimize workflow execution to minimize GitHub Actions billed minutes:**

- **Trigger optimization**: Only run workflows on relevant file changes (use path filters)
- **Matrix builds**: Keep job matrices minimal, avoid unnecessary combinations
- **Dependency caching**: Use Go module caching to reduce build times
- **Skip trivial changes**: Use conditionals to skip jobs for docs-only or trivial changes
- **Job filters**: Apply conditionals to avoid wasteful runs (e.g., skip deployment on forks)

## Workflow Architecture Overview

The CI/CD pipeline consists of 10 specialized workflows with different service orchestration approaches:

| Workflow | File | Services | Connectivity Verification | Primary Purpose |
|----------|------|----------|---------------------------|-----------------|
| Quality | `ci-quality.yml` | None | N/A | Code quality, linting, formatting, builds |
| Coverage | `ci-coverage.yml` | None | N/A | Test coverage collection and reporting |
| Benchmark | `ci-benchmark.yml` | None | N/A | Performance benchmarking |
| GitLeaks | `ci-gitleaks.yml` | None | N/A | Secrets scanning |
| SAST | `ci-sast.yml` | None | N/A | Static application security testing |
| Race | `ci-race.yml` | None | N/A | Race condition detection |
| Fuzz | `ci-fuzz.yml` | None | N/A | Fuzz testing for key generation and digests |
| DAST | `ci-dast.yml` | PostgreSQL | Bash/curl | Dynamic application security testing |
| E2E | `ci-e2e.yml` | Full Docker stack | Go test infra | End-to-end integration testing |
| Load | `ci-load.yml` | Full Docker stack | Bash/curl | Load and performance testing |

## Service Connectivity Verification Patterns

### Pattern 1: No Service Connectivity Verification

**When to Use**: Workflows that perform static analysis, unit tests, builds, or scans without starting services

**Workflows**: `ci-quality.yml`, `ci-coverage.yml`, `ci-benchmark.yml`, `ci-gitleaks.yml`, `ci-sast.yml`, `ci-race.yml`, `ci-fuzz.yml`

---

### Pattern 2: Go-Based E2E Infrastructure

**When to Use**: Workflows that require comprehensive integration testing with full Docker Compose orchestration

**Workflow**: `ci-e2e.yml`

**Key Components**:
```go
// internal/test/e2e/infrastructure.go
- Docker Compose orchestration (start/stop services)
- Multi-stage health checking (Docker health + HTTP connectivity)
- Exponential backoff retry logic

// internal/test/e2e/docker_health.go  
- Parse `docker compose ps --format json` output
- Handle 3 service types: jobs, service with internal healthcheck, service with external healthcheck job
- Complex, comprehensive health status determination

// internal/test/e2e/http_utils.go
- CreateInsecureHTTPClient() with InsecureSkipVerify for self-signed certs
- HTTP GET requests with context for timeouts
```

**Why Go Infrastructure**:
- Cross-platform (Windows dev, Linux CI runners, macOS dev)
- Complex, comprehensive error handling
- Better debugging with stack traces

---

### Pattern 3: Non-Go API Tests (DAST, Load)

**When to Use**: Workflows that need simple service readiness check (ZAP, Nuclei, Gatling)

**Workflows**: `ci-dast.yml`, `ci-load.yml`

# Check HTTPS endpoints (cryptoutil uses self-signed certs in CI)
```
check_endpoint "https://127.0.0.1:8080/ui/swagger/doc.json" "cryptoutil-sqlite"
check_endpoint "https://127.0.0.1:8081/ui/swagger/doc.json" "cryptoutil-postgres-1"
check_endpoint "https://127.0.0.1:8082/ui/swagger/doc.json" "cryptoutil-postgres-2"
```

## Configuration Management

### Application Configuration (Production/CI Deployments)
- **ALWAYS use config files** for production and CI application deployments
- **Example**: `cryptoutil server start --config configs/production/config.yml`
- **Database**: Config files should specify actual database connections (PostgreSQL for production)
- **CI/CD Pattern**: Copy and modify base config files for different environments rather than using environment variables
- **Why**: Config files are version-controlled, documented, and prevent environment variable naming mistakes
- **NEVER use environment variables for secrets

### Environment Variables (When Necessary)
- **Use sparingly**: Only for emergency overrides or local development when secrets infrastructure isn't available
- Check `config.go` for the exact setting names and their corresponding environment variables

### Test Configuration (Development/Testing)
- **Tests ALWAYS use SQLite in-memory databases**
- When running `cryptoutil server start --dev`, the application automatically switches to SQLite for development/testing

## Go Module Caching Best Practices

### Use `cache: true` on `setup-go` Action
- **Preferred**: `cache: true` on `actions/setup-go@v6`
- **Why**: Automatic, self-healing, prevents tar extraction conflicts
- **Avoid**: Manual `actions/cache@v4` for Go modules (brittle, requires workarounds)

### Cache Key Strategy
- Use `go.sum` hash for cache invalidation
- Include OS in key for cross-platform compatibility
- Consider dependency count for large monorepos

### Troubleshooting
- Cache misses: Check `go.sum` changes
- Cache corruption: Let `setup-go` handle it automatically
- Performance issues: Monitor cache hit rates in workflow logs

## Artifact Management Best Practices

### Actions Tab Artifacts (Downloadable)
- **ALWAYS upload artifacts to Actions tab** for any generated reports, logs, or outputs that users/developers might need to download
- Use `actions/upload-artifact@v5.0.0` with descriptive names and `if: always()` condition
- Include retention policies: `retention-days: 1` for temporary files, `retention-days: 1-30` for valuable reports (coverage, test results, security scans that developers need to reference)

### Security Tab Integration (SARIF)
- **ALWAYS upload security findings to GitHub Security tab** using `github/codeql-action/upload-sarif@v3`
- Upload SARIF files for SAST, DAST, container scanning, and dependency analysis results
- Use `if: always() && hashFiles('file.sarif') != ''` to avoid failures when no issues found
- **Dual upload pattern**: Upload both to Security tab (for visualization) AND Actions tab (for downloadability)

### Additional Best Practices
- Use consistent artifact naming conventions across workflows
- Include timestamps or run IDs in artifact names when multiple runs possible
- Compress large artifacts to reduce storage costs
- Document artifact contents in workflow comments
- Clean up temporary artifacts within workflows to avoid clutter

## Act Workflow Testing

### CRITICAL: Use cmd/workflow Utility

**ALWAYS use `go run ./cmd/workflow` for running act workflows**

```bash
# Quick DAST scan (3-5 minutes)
go run ./cmd/workflow -workflows=dast -inputs="scan_profile=quick"

# Full DAST scan (10-15 minutes)
go run ./cmd/workflow -workflows=dast -inputs="scan_profile=full"

# Multiple workflows
go run ./cmd/workflow -workflows=e2e,dast

# Available workflows: quality, coverage, benchmark, gitleaks, sast, race, fuzz, e2e, dast, load
```

### Timing Expectations
- **Quick profile**: 3-5 minutes (Nuclei + ZAP scans)
- **Full profile**: 10-15 minutes (comprehensive scanning)
- **Deep profile**: 20-25 minutes (exhaustive scanning)

### Common Mistakes to AVOID
âŒ **NEVER**: Use `-t` timeout flag or check output too early
âŒ **NEVER**: `Start-Sleep -Seconds 60` (way too short)
âŒ **NEVER**: `Get-Content -Wait` on log while scan runs (kills process)
âŒ **NEVER**: Run act commands directly without monitoring

âœ… **ALWAYS**: Use `cmd/workflow` for automated monitoring
âœ… **ALWAYS**: Review generated workflow analysis markdown files
âœ… **ALWAYS**: Let utility complete before checking outputs

## Diagnostic Logging Standards

### CRITICAL: Consistent Diagnostic Logging Required

**ALL workflow steps performing significant operations (>10s) MUST include timing diagnostics:**

```yaml
- name: Step Name
  run: |
    echo "ðŸ“‹ Starting operation..."
    START_TIME=$(date +%s)
    echo "ðŸ“… Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
    # ... operations ...
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))
    echo "ðŸ“… End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
    echo "â±ï¸ Operation completed in: ${DURATION}s"
```

### When to Apply
- **REQUIRED**: Steps >10s, complex operations, critical path, external services, artifact generation
- **OPTIONAL**: Fast steps (<5s), simple setup/cleanup, informational only

### Standards
- **Timing**: `START_TIME=$(date +%s)`, `DURATION=$((END_TIME - START_TIME))`
- **Emojis**: ðŸ“‹ start, ðŸ“… timestamps, â±ï¸ duration, âœ… success, âŒ error, ðŸ” scan, ðŸ“¦ artifacts, ðŸ§¹ cleanup
- **Benefits**: Performance monitoring, debugging, trend analysis, resource planning
