# $schema: https://json.schemastore.org/github-workflow.json
# https://docs.github.com/en/actions/reference/workflows-and-actions/workflow-syntax

# WORKFLOW: Dynamic Application Security Testing (DAST)
# PURPOSE: Security vulnerability scanning using Nuclei + ZAP against running services
# DEPENDENCIES: Docker Compose stack (cryptoutil services + PostgreSQL)
# EXPECTED DURATION: Quick=3-5min, Full=10-15min, Deep=20-25min (depends on scan_profile input)
# TIMEOUT: 90min (allows deep scans + ZAP full crawl + shared CPU latency)
# CRITICAL PATH: Docker Compose stack startup (30-60s) + ZAP full scan (10-20min for deep profile)
# OPTIMIZATION OPPORTUNITY: Consider splitting Nuclei (fast) vs ZAP (slow) into separate workflows

name: CI - DAST Security Testing
# CROSS-PLATFORM COMPATIBILITY: All file references in this workflow MUST use relative paths
# to support both GitHub Actions Ubuntu runners and Windows `act` local runner testing.
# Absolute paths (e.g., C:\...) break cross-platform compatibility.
# Example: Use './deployments/cryptoutil-suite/compose.yml'
#
# IMPORTANT: Test locally with act (NO TIMEOUT - workflows take 3-25 minutes):
#   RECOMMENDED: Use the automated Go utility (handles timeouts, monitoring, and analysis):
#     go run ./cmd/workflow -workflows=dast -inputs="scan_profile=quick"
#     go run ./cmd/workflow -workflows=dast -inputs="scan_profile=full"
#     go run ./cmd/workflow -workflows=dast -inputs="scan_profile=deep"
#
#   ALTERNATIVE: Direct act commands (manual monitoring required):
#     [Console]::OutputEncoding = [System.Text.Encoding]::UTF8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=quick --artifact-server-path ./workflow-reports/dast 2>&1 | Out-File -FilePath .\workflow-reports\dast\act-dast.log -Encoding utf8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=full --artifact-server-path ./workflow-reports/dast 2>&1 | Out-File -FilePath .\workflow-reports\dast\act-dast.log -Encoding utf8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=deep --artifact-server-path ./workflow-reports/dast 2>&1 | Out-File -FilePath .\workflow-reports\dast\act-dast.log -Encoding utf8
# MANUAL CHECK: Get-Content .\workflow-reports\dast\act-dast.log -Tail 100
# TIMING: Quick=3-5min, Full=10-15min, Deep=20-25min
# OUTPUT CONVENTION: All scan outputs and reports must be written to ./workflow-reports/dast/ directory

on:
  push:
    branches: [ main ]
    # SHARED PATHS-IGNORE CONFIGURATION - Keep synchronized with pull_request below
    paths-ignore:
      - 'docs/**'
      - '**/*.md'
      - '.github/copilot-instructions.md'
      - '.github/instructions/**'
      - 'workflow-reports/**'
      - 'nohup.out'
      - 'LICENSE'
      - '.editorconfig'
      - '.gitignore'
      - '.gitattributes'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/pull_request_template.md'
      - '.github/dependabot.yml'
      - '**/*.log'
      - '**/*.sarif'
  pull_request:
    branches: [ main ]
    # SHARED PATHS-IGNORE CONFIGURATION - Keep synchronized with push above
    paths-ignore:
      - 'docs/**'
      - '**/*.md'
      - '.github/copilot-instructions.md'
      - '.github/instructions/**'
      - 'workflow-reports/**'
      - 'nohup.out'
      - 'LICENSE'
      - '.editorconfig'
      - '.gitignore'
      - '.gitattributes'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/pull_request_template.md'
      - '.github/dependabot.yml'
      - '**/*.log'
      - '**/*.sarif'
  schedule:
    # Run DAST weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target URL for DAST scanning (default: https://127.0.0.1:8080)'
        required: false
        default: 'https://127.0.0.1:8080'
      scan_profile:
        description: 'Scan profile for performance optimization'
        required: false
        default: 'quick'
        type: choice
        options:
          - quick
          - full
          - deep

env:
  SCAN_PROFILE: ${{ github.event.inputs.scan_profile || 'full' }}

  # HTTPS endpoints use 127.0.0.1 (not localhost) for predictable IPv4 behavior and TLS certificate compatibility
  APP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}
  APP_PRIVATE_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:9090' }}

  # Nuclei runs inside GitHub Actions runner/act container - can use 127.0.0.1 directly
  NUCLEI_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}

  # ZAP runs in separate Docker container - must use host.docker.internal to reach host network
  ZAP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}
  # ZAP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://host.docker.internal:8080' }}

  APP_BIND_PUBLIC_PROTOCOL: https
  APP_BIND_PUBLIC_ADDRESS: 0.0.0.0
  APP_BIND_PUBLIC_PORT: 8080

  APP_BIND_PRIVATE_PROTOCOL: https
  APP_BIND_PRIVATE_ADDRESS: 127.0.0.1
  APP_BIND_PRIVATE_PORT: 9090

  # Database uses localhost (not 127.0.0.1) for PostgreSQL client library optimization
  POSTGRES_HOST: localhost
  POSTGRES_PORT: 5432
  POSTGRES_NAME: cryptoutil_test
  POSTGRES_USER: cryptoutil
  POSTGRES_PASS: cryptoutil_test_password

jobs:
  dast-security-scan:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:18
        env:
          POSTGRES_DB: ${{ env.POSTGRES_NAME }}
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASS }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432 # env context is not available in the services.ports section

    permissions:
      contents: read
      security-events: write
      actions: read

    steps:
    - name: Checkout code
      # https://github.com/actions/checkout/releases (v6.0.0, 2025-11-11)
      uses: actions/checkout@v6.0.0
      with:
        sparse-checkout-cone-mode: false  # Disabled for cross-platform compatibility between GitHub Actions and act local runner

    - name: Begin Workflow Job
      id: begin-workflow-job
      uses: ./.github/actions/workflow-job-begin

    - name: Setup directories and Nuclei templates version
      id: nuclei-version
      run: |
        echo "üîß Setting up directories and Nuclei templates..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Create required directories
        mkdir -p ./workflow-reports/dast configs/test
        # Ephemeral mode: always use latest nuclei templates
        echo "templates_version=LATEST" >> $GITHUB_OUTPUT
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Directory setup completed in: ${DURATION}s"

    - name: Diagnostic - System information
      if: always()
      run: |
        echo "üîç Collecting system diagnostic information..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        mkdir -p ./workflow-reports/dast
        SYSINFO=workflow-reports/dast/system-info.txt
        echo "Date: $(date -u)" > $SYSINFO
        echo "===== uname -a =====" >> $SYSINFO
        uname -a >> $SYSINFO 2>&1 || true
        echo "\n===== lsb_release / os-release =====" >> $SYSINFO
        [ -f /etc/os-release ] && cat /etc/os-release >> $SYSINFO || true
        echo "\n===== docker version/info =====" >> $SYSINFO
        docker version >> $SYSINFO 2>&1 || true
        docker info >> $SYSINFO 2>&1 || true
        echo "\n===== docker network ls =====" >> $SYSINFO
        docker network ls >> $SYSINFO 2>&1 || true
        echo "\n===== docker ps -a =====" >> $SYSINFO
        docker ps -a >> $SYSINFO 2>&1 || true
        echo "\n===== Top processes (top -b -n1 | head -30) =====" >> $SYSINFO
        (top -b -n1 | head -30) >> $SYSINFO 2>&1 || ps aux --sort=-%mem | head -30 >> $SYSINFO 2>&1 || true
        echo "\n===== Selected environment variables =====" >> $SYSINFO
        # Print only non-secret env vars that are helpful for diagnostics
        for v in GO_VERSION SCAN_PROFILE APP_PUBLIC_TARGET_URL APP_PRIVATE_TARGET_URL NUCLEI_PUBLIC_TARGET_URL ZAP_PUBLIC_TARGET_URL APP_BIND_PUBLIC_PORT APP_BIND_PRIVATE_PORT POSTGRES_HOST POSTGRES_PORT; do
          echo "$v=${!v}" >> $SYSINFO 2>&1 || true
        done
        echo "\nWrote system diagnostics to: $SYSINFO"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è System diagnostics completed in: ${DURATION}s"

    - name: Cache Nuclei Templates
      id: cache-nuclei-templates
      # https://github.com/actions/cache/releases (v4.3.0, 2025-04-18)
      uses: actions/cache@v4.3.0
      with:
        path: /root/nuclei-templates
        key: nuclei-templates-${{ runner.os }}-${{ steps.nuclei-version.outputs.templates_version }}
        restore-keys: |
          nuclei-templates-${{ runner.os }}-

    - name: Set up Go and validate dependencies
      uses: ./.github/actions/go-setup
      with:
        go-version: ${{ steps.begin-workflow-job.outputs.go-version }}
        go-mod-download: true
        go-mod-verify: true
        go-mod-tidy: false  # DAST builds/tests but skips tidy to avoid modifying go.mod/go.sum during scans

    - name: Pre-pull Docker images (parallel)
      uses: ./.github/actions/docker-images-pull
      with:
        images: |
          postgres:18
          ghcr.io/zaproxy/zaproxy:stable

    - name: Build application
      run: |
        echo "üî® Building cryptoutil application..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        go build -o cryptoutil ./cmd/cryptoutil
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Application build completed in: ${DURATION}s"

    # See internal\common\config\config.go for configuration options
    - name: Start application for DAST testing
      run: |
        echo "üöÄ Starting cryptoutil application for DAST testing..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Create unseal secret and config files
        echo "dast-simple-unseal-secret-value-1" > ./configs/test/dast-simple-unseal-secret-value-1.secret
        cat > ./configs/test/config.yml << 'CONFIGEOF'
        log-level: "DEBUG"
        verbose: true
        dev-mode: true
        rate-limit: 1000
        bind-public-protocol: "https"
        bind-public-address: "127.0.0.1"
        bind-public-port: 8080
        bind-private-protocol: "https"
        bind-private-address: "127.0.0.1"
        bind-private-port: 9090
        database-url: "postgres://cryptoutil:cryptoutil_test_password@127.0.0.1:5432/cryptoutil_test?sslmode=disable"
        unseal-mode: "1-of-1"
        unseal-files:
          - ./configs/test/dast-simple-unseal-secret-value-1.secret
        CONFIGEOF
        # Remove leading spaces from the config file (heredoc preserves indentation)
        sed -i 's/^        //' ./configs/test/config.yml

        # Start application in background, capture PID for cleanup; use nohup to avoid termination on shell exit
        mkdir -p workflow-reports/dast
        # Redirect stdout/stderr to files under workflow-reports/dast for easier post-mortem
        nohup ./cryptoutil kms start --config configs/test/config.yml > workflow-reports/dast/cryptoutil.stdout 2> workflow-reports/dast/cryptoutil.stderr &
        APP_PID=$!
        echo "APP_PID=$APP_PID" >> $GITHUB_ENV
        echo "Wrote app logs to: workflow-reports/dast/cryptoutil.stdout and workflow-reports/dast/cryptoutil.stderr"

        # Enhanced readiness probe with retry/backoff logic
        echo "Waiting for application to be ready..."
        MAX_ATTEMPTS=30
        ATTEMPT=0
        BACKOFF=1
        READY=false

        # Progressive health check: private health endpoints first, then public Swagger
        HEALTH_ENDPOINTS=(
          "${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/readyz"
          # "${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/livez"
          # "${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        )

        while [ $ATTEMPT -lt $MAX_ATTEMPTS ] && [ "$READY" != "true" ]; do
          ATTEMPT=$((ATTEMPT + 1))
          echo "Attempt $ATTEMPT/$MAX_ATTEMPTS (backoff: ${BACKOFF}s)"

          for endpoint in "${HEALTH_ENDPOINTS[@]}"; do
            echo "Testing: $endpoint"
            # Use slightly generous timeouts for containerized environments
            # Save response headers and body to files for debugging
            SAFE_NAME=$(echo "$endpoint" | sed -e 's/[^a-zA-Z0-9]/_/g' | cut -c1-80)
            if curl -sk --connect-timeout 10 --max-time 15 -D workflow-reports/dast/health_${SAFE_NAME}.headers -o workflow-reports/dast/health_${SAFE_NAME}.body "$endpoint" >/dev/null 2>&1; then
              echo "‚úì Application ready at: $endpoint (output saved to workflow-reports/dast/health_${SAFE_NAME}.*)"
              READY=true
              break
            else
              echo "‚úó Not ready: $endpoint"
            fi
          done

          if [ "$READY" != "true" ]; then
            sleep $BACKOFF
            # Exponential backoff with max 5 seconds
            BACKOFF=$((BACKOFF < 5 ? BACKOFF + 1 : 5))
          fi
        done

        if [ "$READY" != "true" ]; then
          echo "‚ùå Application failed to become ready within timeout"
          echo ""
          echo "=== Application STDERR (last 100 lines) ==="
          tail -100 workflow-reports/dast/cryptoutil.stderr 2>/dev/null || echo "(no stderr file found)"
          echo ""
          echo "=== Application STDOUT (last 50 lines) ==="
          tail -50 workflow-reports/dast/cryptoutil.stdout 2>/dev/null || echo "(no stdout file found)"
          echo ""
          exit 1
        fi

        echo "‚úÖ Application is ready and responsive"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Application startup completed in: ${DURATION}s"

    - name: Diagnostic - Verify connectivity from runner and Docker contexts
      id: diagnostic_connectivity
      if: always()
      run: |
        echo "üîç Running connectivity diagnostics..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Diagnostic connectivity checks: quick reachability tests that return concise status codes.
        # Use consistent timeouts for all diagnostic curl calls.
        CURL_CONNECT_TIMEOUT=10
        CURL_MAX_TIMEOUT=15

        echo ""
        echo "üîç Testing connectivity from runner..."
        echo ""

        echo "1. Testing ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/readyz (readiness probe)"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D workflow-reports/dast/connectivity_private_readyz.headers -o workflow-reports/dast/connectivity_private_readyz.body ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/readyz || true
        echo "Runner->private_readyz: $(wc -c < workflow-reports/dast/connectivity_private_readyz.body 2>/dev/null || echo 0) bytes"
        if [ -s workflow-reports/dast/connectivity_private_readyz.body ]; then
          echo "  ‚úÖ ${{ env.APP_PRIVATE_TARGET_URL }} reachable from runner"
        else
          echo "  ‚ùå ${{ env.APP_PRIVATE_TARGET_URL }} NOT reachable from runner"
        fi

        echo "2. Testing ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D workflow-reports/dast/connectivity_public_swagger.headers -o workflow-reports/dast/connectivity_public_swagger.body ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json || true
        echo "Runner->public_swagger: $(wc -c < workflow-reports/dast/connectivity_public_swagger.body 2>/dev/null || echo 0) bytes"
        if [ -s workflow-reports/dast/connectivity_public_swagger.body ]; then
          echo "  ‚úÖ ${{ env.APP_PUBLIC_TARGET_URL }} reachable from runner"
        else
          echo "  ‚ùå ${{ env.APP_PUBLIC_TARGET_URL }} NOT reachable from runner"
        fi

        echo "3. Testing Nuclei target ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D workflow-reports/dast/connectivity_nuclei.headers -o workflow-reports/dast/connectivity_nuclei.body ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ui/swagger/doc.json || true
        echo "Runner->nuclei_swagger: $(wc -c < workflow-reports/dast/connectivity_nuclei.body 2>/dev/null || echo 0) bytes"
        if [ -s workflow-reports/dast/connectivity_nuclei.body ]; then
          echo "  ‚úÖ Nuclei target reachable from runner"
          echo "NUCLEI_REACHABLE=true" >> $GITHUB_ENV
          echo "NUCLEI_REACHABLE=true" >> $GITHUB_OUTPUT
        else
          echo "  ‚ùå Nuclei target NOT reachable from runner"
          # Also test the root endpoint as fallback
          echo "  Testing fallback: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/"
          curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D workflow-reports/dast/connectivity_nuclei_fallback.headers -o workflow-reports/dast/connectivity_nuclei_fallback.body ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ || true
          if [ -s workflow-reports/dast/connectivity_nuclei_fallback.body ]; then
            echo "  ‚úÖ Nuclei target reachable via fallback endpoint"
            echo "NUCLEI_REACHABLE=true" >> $GITHUB_ENV
            echo "NUCLEI_REACHABLE=true" >> $GITHUB_OUTPUT
          else
            echo "  ‚ùå Nuclei target NOT reachable from runner (including fallback)"
            echo "NUCLEI_REACHABLE=false" >> $GITHUB_ENV
            echo "NUCLEI_REACHABLE=false" >> $GITHUB_OUTPUT
          fi
        fi

        echo ""
        echo "üîç Testing connectivity from Docker container..."
        echo ""

        echo "4. Testing ${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        # Test only the configured ZAP_PUBLIC_TARGET_URL from Docker context
        OUTFILE=workflow-reports/dast/docker_connect_$(echo "${{ env.ZAP_PUBLIC_TARGET_URL }}" | sed -e 's/[^a-zA-Z0-9]/_/g').txt
        if curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D - "${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json" > $OUTFILE 2>&1; then
          echo "  ‚úÖ ${{ env.ZAP_PUBLIC_TARGET_URL }} reachable from Docker container (details: $OUTFILE)"
          echo "ZAP_REACHABLE=true" >> $GITHUB_ENV
          echo "ZAP_REACHABLE=true" >> $GITHUB_OUTPUT
        else
          echo "  ‚ùå ${{ env.ZAP_PUBLIC_TARGET_URL }} NOT reachable from Docker container (details: $OUTFILE)"
          echo "ZAP_REACHABLE=false" >> $GITHUB_ENV
          echo "ZAP_REACHABLE=false" >> $GITHUB_OUTPUT
        fi

        echo "5. Testing ${{ env.APP_PUBLIC_TARGET_URL }} from Docker:"
        if curl -skf --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json -o /dev/null -w "HTTP %{http_code}\n" 2>&1; then
          echo "  ‚úÖ ${{ env.APP_PUBLIC_TARGET_URL }} reachable from Docker"
        else
          echo "  ‚ùå ${{ env.APP_PUBLIC_TARGET_URL }} NOT reachable from Docker"
        fi

        echo ""
        echo "=== Summary ==="
        echo "- ACT public target URL should use: ${{ env.APP_PUBLIC_TARGET_URL }}"
        echo "- ACT private target URL should use: ${{ env.APP_PRIVATE_TARGET_URL }}"
        echo "- Nuclei public target URL should use: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}"
        echo "- ZAP public target URL should use: ${{ env.ZAP_PUBLIC_TARGET_URL }}"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Connectivity diagnostics completed in: ${DURATION}s"

    - name: Capture baseline response headers (immediate)
      if: always()
      run: |
        echo "üìã Capturing baseline response headers..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Capture headers from key API endpoints (app is ready per health check)
        # NOTE: -v flag enables verbose output showing request headers (add back if debugging needed)
        echo "Starting header capture from ${{ env.APP_PUBLIC_TARGET_URL }}..."
        echo "Current directory: $(pwd)"
        echo "Contents of workflow-reports/dast before capture:"
        ls -la workflow-reports/dast/ || echo "workflow-reports/dast directory not found"

        echo "Creating header baseline file: workflow-reports/dast/response-headers.txt"
        {
          echo "# Header Baseline ($(date -u))"

          echo "## Private - readyz"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/readyz 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/readyz - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo -e "\n## Private - livez"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/livez 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PRIVATE_TARGET_URL }}/admin/api/v1/livez - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo "## Swagger UI (main page)"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/ 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo -e "\n## Swagger API spec (doc.json)"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo -e "\n## Browser API - CSRF token endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/browser/api/v1/csrf-token"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo -e "\n## Browser API - Elastic Keys endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/browser/api/v1/elastickeys"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2

          echo -e "\n## Service API - Elastic Keys endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/service/api/v1/elastickeys"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ‚úÖ Success" >&2 || echo "  ‚ùå Failed" >&2
        } > workflow-reports/dast/response-headers.txt

        echo "Verifying file creation: workflow-reports/dast/response-headers.txt"
        if [ -f "workflow-reports/dast/response-headers.txt" ]; then
          echo "File created successfully: workflow-reports/dast/response-headers.txt"
          echo "File size: $(wc -c < workflow-reports/dast/response-headers.txt) bytes"
          echo "File contents preview (first 2 lines):"
          echo "########################################"
          head -2 workflow-reports/dast/response-headers.txt
          echo "########################################"
        else
          echo "File NOT created: workflow-reports/dast/response-headers.txt"
        fi

        echo "Contents of workflow-reports/dast after capture: workflow-reports/dast/response-headers.txt"
        ls -la workflow-reports/dast/ || echo "workflow-reports/dast directory not found"

        echo "Header capture process completed: workflow-reports/dast/response-headers.txt"
        # Also capture a short app log tail for quick inspection
        if [ -f workflow-reports/dast/cryptoutil.stdout ]; then
          echo "\n===== APP STDOUT (tail 200) =====" >> workflow-reports/dast/system-info.txt || true
          tail -n 200 workflow-reports/dast/cryptoutil.stdout >> workflow-reports/dast/system-info.txt || true
        fi
        if [ -f workflow-reports/dast/cryptoutil.stderr ]; then
          echo "\n===== APP STDERR (tail 200) =====" >> workflow-reports/dast/system-info.txt || true
          tail -n 200 workflow-reports/dast/cryptoutil.stderr >> workflow-reports/dast/system-info.txt || true
        fi
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Header capture completed in: ${DURATION}s"

    # Official ZAP actions for both GitHub-hosted runners and act-local
    - name: Start ZAP DAST scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      run: |
        echo "üï∑Ô∏è Starting OWASP ZAP DAST scan..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "START_TIME=$START_TIME" >> $GITHUB_ENV

    - name: Run OWASP ZAP DAST Scan
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      continue-on-error: true  # ZAP exit code 3 (informational findings) treated as failure by action
      # https://github.com/zaproxy/action-full-scan/releases (v0.13.0, 2025-02-19)
      uses: zaproxy/action-full-scan@v0.13.0
      with:
        target: ${{ env.ZAP_PUBLIC_TARGET_URL }}
        docker_name: 'ghcr.io/zaproxy/zaproxy:stable'
        rules_file_name: '.zap/rules.tsv'
        # Cookie ignore list: Only _csrf in cryptoutil; JSESSIONID and csrftoken are from other stacks
        # -d: debug/verbose logging, all -config options must be inside -z quotes
        cmd_options: '-a -j -m 5 -T 30 -d -r zap-report.html -w zap-report.md -x zap-report.xml -J zap-report.json -z "-config rules.cookie.ignorelist=_csrf -config api.addrs.addr.name=.* -config api.addrs.addr.regex=true -config connection.hostHeader=127.0.0.1:8080"'
        allow_issue_writing: false
        artifact_name: 'zap-report'
        fail_action: 'false'  # Only controls exit code 1/2, not 3

    - name: Complete ZAP DAST scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      run: |
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è ZAP DAST scan completed in: ${DURATION}s"

    - name: Collect ZAP DAST Scan artifacts
      if: always()
      run: |
        echo "üì¶ Collecting ZAP DAST scan artifacts..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        for artifact in zap-report.{html,json,xml,md} report_json.json report_md.md report_html.html; do
          if [ -f "./workflow-reports/dast/$artifact" ]; then
            echo "  ‚úÖ Already exists: workflow-reports/dast/$artifact"
          elif [ -f "$artifact" ]; then
            # Move ZAP full scan artifacts to workflow-reports/dast
            if mv "$artifact" ./workflow-reports/dast/; then
              echo "  ‚úÖ Moved: $artifact -> workflow-reports/dast/"
            else
              echo "  ‚ùå Failed to move: $artifact"
            fi
          else
            echo "  ‚è≠ Not found: $artifact (skipped)"
          fi
        done
        echo "ZAP DAST scan artifact collection completed"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è ZAP artifact collection completed in: ${DURATION}s"

    - name: Start ZAP API scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      run: |
        echo "üï∑Ô∏è Starting OWASP ZAP API scan..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "START_TIME=$START_TIME" >> $GITHUB_ENV

    - name: Run OWASP ZAP API Scan
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      continue-on-error: true  # ZAP exit code 3 (informational findings) treated as failure by action
      # https://github.com/zaproxy/action-api-scan/releases (v0.10.0, 2025-01-08)
      uses: zaproxy/action-api-scan@v0.10.0
      with:
        target: '${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json'
        docker_name: 'ghcr.io/zaproxy/zaproxy:stable'
        format: openapi
        cmd_options: '-a -j -T 30 -r zap-api-report.html -J zap-api-report.json -z "-config connection.hostHeader=127.0.0.1:8080"'
        fail_action: 'false'  # Only controls exit code 1/2, not 3
        allow_issue_writing: false
        artifact_name: 'zap-api-report'

    - name: Complete ZAP API scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      run: |
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è ZAP API scan completed in: ${DURATION}s"

    - name: Collect ZAP API Scan artifacts
      if: always()
      run: |
        echo "üì¶ Collecting ZAP API scan artifacts..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Move ZAP API scan artifacts to workflow-reports/dast immediately after generation
        for artifact in zap-api-report.{html,json} report_json.json report_md.md report_html.html; do
          if [ -f "./workflow-reports/dast/$artifact" ]; then
            echo "  ‚úÖ Already exists: workflow-reports/dast/$artifact (skipped)"
          elif [ -f "$artifact" ]; then
            if mv "$artifact" ./workflow-reports/dast/; then
              echo "  ‚úÖ Moved: $artifact -> workflow-reports/dast/"
            else
              echo "  ‚ùå Failed to move: $artifact"
            fi
          else
            echo "  ‚è≠ Not found: $artifact (skipped)"
          fi
        done
        echo "ZAP API scan artifact collection completed"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è ZAP API artifact collection completed in: ${DURATION}s"

    # Doc: https://github.com/projectdiscovery/nuclei-action
    # NOTE: Nuclei runs via composite action inside the GitHub Actions runner/act container,
    # so it can access 127.0.0.1:8080 directly without Docker networking complications.
    - name: Set Nuclei scan configuration based on profile
      id: nuclei_config
      run: |
        case "$SCAN_PROFILE" in
          "quick")
            echo "timeout=60" >> $GITHUB_OUTPUT
            echo "concurrency=12" >> $GITHUB_OUTPUT
            echo "rate_limit=100" >> $GITHUB_OUTPUT
            echo "templates=cves/2023/,cves/2024/,vulnerabilities/,security-misconfiguration/generic/" >> $GITHUB_OUTPUT
            echo "description=Quick scan (PRs): ~2-3 minutes, recent CVEs and basic misconfigurations" >> $GITHUB_OUTPUT
            ;;
          "deep")
            echo "timeout=1200" >> $GITHUB_OUTPUT
            echo "concurrency=32" >> $GITHUB_OUTPUT
            echo "rate_limit=300" >> $GITHUB_OUTPUT
            echo "templates=" >> $GITHUB_OUTPUT
            echo "description=Deep scan (scheduled): ~15-20 minutes, all templates" >> $GITHUB_OUTPUT
            ;;
          *) # full (default)
            echo "timeout=600" >> $GITHUB_OUTPUT
            echo "concurrency=24" >> $GITHUB_OUTPUT
            echo "rate_limit=200" >> $GITHUB_OUTPUT
            echo "templates=cves/,vulnerabilities/,security-misconfiguration/,default-logins/,exposed-panels/" >> $GITHUB_OUTPUT
            echo "description=Full scan (main push): ~8-10 minutes, comprehensive coverage" >> $GITHUB_OUTPUT
            ;;
        esac
        echo "Profile: $SCAN_PROFILE"
        echo "Configuration set for profile: $SCAN_PROFILE"

    - name: Start Nuclei scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.NUCLEI_REACHABLE == 'true' }}
      run: |
        echo "üîç Starting Nuclei vulnerability scan..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "START_TIME=$START_TIME" >> $GITHUB_ENV

    - name: Nuclei - Vulnerability Scan (${{ steps.nuclei_config.outputs.description }})
      if: ${{ steps.diagnostic_connectivity.outputs.NUCLEI_REACHABLE == 'true' }}
      id: nuclei_scan
      # https://github.com/projectdiscovery/nuclei-action (main branch, no versioned releases)
      uses: projectdiscovery/nuclei-action@main
      continue-on-error: true  # Continue even if nuclei finds vulnerabilities (exit code 1) or has errors
      with:
        target: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}
        user-agent: "User-Agent:'Nuclei - Vulnerability Scan (Have a nice day)'"
        # Exclude tcp/javascript protocol templates to avoid scanning infrastructure services (SSH:22, PostgreSQL:5432, RPC:111)
        # See: https://github.com/orgs/projectdiscovery/discussions/5159
        # Use .nuclei-ignore file to suppress known false positives
        flags: "-c ${{ steps.nuclei_config.outputs.concurrency }} -rl ${{ steps.nuclei_config.outputs.rate_limit }} -timeout ${{ steps.nuclei_config.outputs.timeout }} -stats -ept tcp,javascript -ei .nuclei-ignore${{ steps.nuclei_config.outputs.templates && format(' -t {0}', steps.nuclei_config.outputs.templates) || '' }}"

    - name: Complete Nuclei scan timing
      if: ${{ steps.diagnostic_connectivity.outputs.NUCLEI_REACHABLE == 'true' }}
      run: |
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Nuclei vulnerability scan completed in: ${DURATION}s"

    - name: Set dummy token for local act runs
      if: ${{ github.actor == 'nektos/act' }}
      run: |
        if [ -n "${GITHUB_TOKEN}" ]; then
          echo "GITHUB_TOKEN already set; leaving existing token in place";
        else
          echo "Setting dummy GITHUB_TOKEN for act local run to avoid upload-sarif failure";
          echo "GITHUB_TOKEN=act-dummy-token" >> $GITHUB_ENV;
        fi

    - name: Collect Nuclei scan artifacts
      if: always()
      run: |
        echo "üì¶ Collecting Nuclei scan artifacts..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Move Nuclei artifacts to workflow-reports/dast
        [ -f "nuclei.log" ] && mv nuclei.log ./workflow-reports/dast/ || true
        [ -f "nuclei.sarif" ] && mv nuclei.sarif ./workflow-reports/dast/ || true
        [ -f "nuclei-templates.version" ] && mv nuclei-templates.version ./workflow-reports/dast/ || true

        # For GitHub runs, copy SARIF back to root for upload-sarif action
        if [ "${{ github.actor }}" != "nektos/act" ] && [ -f "./workflow-reports/dast/nuclei.sarif" ]; then
          cp ./workflow-reports/dast/nuclei.sarif nuclei.sarif
        fi
        echo "Nuclei scan artifacts collected"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Nuclei artifact collection completed in: ${DURATION}s"

    - name: Post-collect artifact listing
      if: always()
      run: |
        echo "üìã Generating artifact listing..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "Artifact collection complete"
        # Produce a short diagnostic listing of artifacts for easier analysis
        echo "===== WORKFLOW-REPORTS/DAST DIR =====" > workflow-reports/dast/artifact-listing.txt
        ls -la workflow-reports/dast/ >> workflow-reports/dast/artifact-listing.txt 2>&1 || true
          echo "Wrote artifact listing to workflow-reports/dast/artifact-listing.txt"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Artifact listing completed in: ${DURATION}s"

    - name: Capture container logs
      if: always()
      run: |
        echo "üìã Capturing Docker container logs..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        mkdir -p workflow-reports/dast/container-logs

        # List all containers for reference
        echo "=== Docker Containers ===" > workflow-reports/dast/container-logs/containers.txt
        docker ps -a --format "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}" >> workflow-reports/dast/container-logs/containers.txt 2>&1 || echo "No containers found or docker not available" >> workflow-reports/dast/container-logs/containers.txt

        # Capture logs from relevant containers (ZAP, postgres service containers, etc.)
        # Use a broad pattern to catch any containers that might be related
        for container in $(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "(zap|postgres|cryptoutil|grafana|otel|compose)" | head -20); do
          echo "Capturing logs for container: $container"
          if docker logs "$container" > "workflow-reports/dast/container-logs/${container}.log" 2>&1; then
            echo "‚úÖ Successfully captured logs for: $container ($(wc -l < "workflow-reports/dast/container-logs/${container}.log") lines)"
          else
            echo "‚ùå Failed to capture logs for: $container" >> workflow-reports/dast/container-logs/errors.txt
          fi
        done

        # Also capture Docker system information
        docker info > workflow-reports/dast/container-logs/docker-info.txt 2>&1 || echo "Docker info not available" > workflow-reports/dast/container-logs/docker-info.txt
        docker system df > workflow-reports/dast/container-logs/docker-df.txt 2>&1 || echo "Docker system df not available" > workflow-reports/dast/container-logs/docker-df.txt

        echo "Container log capture completed"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Container log capture completed in: ${DURATION}s"

    - name: Upload container logs
      if: always()
      # https://github.com/actions/upload-artifact/releases (v5.0.0, 2025-04-21)
      uses: actions/upload-artifact@v5.0.0
      with:
        name: container-logs
        path: workflow-reports/dast/container-logs/
        retention-days: 1

    - name: GitHub Workflow artifacts
      if: ${{ always() && github.actor != 'nektos/act' }}
      # https://github.com/actions/upload-artifact/releases (v5.0.0, 2025-04-21)
      uses: actions/upload-artifact@v5.0.0
      with:
        name: dast-workflow-reports
        path: |
          workflow-reports/dast/nuclei.log
          workflow-reports/dast/nuclei.sarif
          workflow-reports/dast/response-headers.txt
          workflow-reports/dast/cryptoutil.stdout
          workflow-reports/dast/cryptoutil.stderr
          workflow-reports/dast/system-info.txt
        retention-days: 1

    - name: GitHub Security Dashboard Alerts update
      # https://github.com/github/codeql-action/releases (v3.28.19, 2025-11-06)
      uses: github/codeql-action/upload-sarif@v3.28.19
      # Skip entirely when running under act; also ensure SARIF file actually exists
      if: ${{ github.actor != 'nektos/act' && hashFiles('nuclei.sarif') != '' }}
      with:
        sarif_file: nuclei.sarif
      env:
        # Use real token in GitHub hosted runner
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate Security Summary
      if: always()
      run: |
        echo "üìä Generating DAST security summary..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        SUMMARY_FILE=workflow-reports/dast/act-status.txt
        {
          echo "# DAST Security Scan Results"
          echo ""
          echo "**Profile:** ${{ env.SCAN_PROFILE }} (${{ steps.nuclei_config.outputs.description }})"
          echo "**Nuclei Target:** ${{ env.NUCLEI_PUBLIC_TARGET_URL }} | **ZAP Target:** ${{ env.ZAP_PUBLIC_TARGET_URL }}"
          echo "**Date:** $(date -u)"
          echo ""
          echo "## Scan Coverage"
          [ -f "workflow-reports/dast/nuclei.log" ] && echo "- ‚úÖ **Nuclei Scan**" || echo "- ‚è≠ **Nuclei Scan:** Skipped"
          ls zap-*-report.html >/dev/null 2>&1 && echo "- ‚úÖ **OWASP ZAP Scans**" || echo "- ‚è≠ **OWASP ZAP Scans:** Disabled"
          echo ""
          echo "## Generated Reports"
          [ -f workflow-reports/dast/nuclei.log ] && echo "- Nuclei Log/SARIF" || true
          [ -f workflow-reports/dast/response-headers.txt ] && echo "- Security Headers" || true
          ls zap-*-report.html >/dev/null 2>&1 && echo "- ZAP Reports" || true
          echo ""
          echo "## Diagnostic summary"
          echo "NUCLEI_REACHABLE=${NUCLEI_REACHABLE:-unset}"
          echo "ZAP_REACHABLE=${ZAP_REACHABLE:-unset}"
          echo "APP_PID=${APP_PID:-unset}"
          echo "APP_LOGS: workflow-reports/dast/cryptoutil.stdout (exists=$( [ -f workflow-reports/dast/cryptoutil.stdout ] && echo yes || echo no))"
          echo "APP_ERRS: workflow-reports/dast/cryptoutil.stderr (exists=$( [ -f workflow-reports/dast/cryptoutil.stderr ] && echo yes || echo no))"
          echo "System diagnostics file: workflow-reports/dast/system-info.txt"
        } | tee -a $GITHUB_STEP_SUMMARY > $SUMMARY_FILE
        echo "Wrote final analysis summary to: $SUMMARY_FILE"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è Security summary generation completed in: ${DURATION}s"

    - name: Cleanup
      if: always()
      run: |
        echo "üßπ Starting DAST cleanup..."
        START_TIME=$(date +%s)
        echo "üìÖ Start: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        # Stop application
        [ -n "${APP_PID:-}" ] && { kill "$APP_PID" 2>/dev/null || true; sleep 1; kill -9 "$APP_PID" 2>/dev/null || true; }

        # Stop and remove containers
        docker compose -f ./deployments/cryptoutil-suite/compose.yml down -v --remove-orphans || true

        # Clean up any leftover containers/networks
        docker system prune -f || true

        # Remove any temporary files created during the scan
        rm -f nuclei.log nuclei.sarif nuclei-templates.version || true

        echo "DAST cleanup completed"
        END_TIME=$(date +%s)
        DURATION=$((END_TIME - START_TIME))
        echo "üìÖ End: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"
        echo "‚è±Ô∏è DAST cleanup completed in: ${DURATION}s"

    - name: DAST summary
      if: always()
      uses: ./.github/actions/workflow-job-end
