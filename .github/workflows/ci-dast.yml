name: CI - DAST Security Testing
# IMPORTANT: Test locally with act (NO TIMEOUT - workflows take 3-25 minutes):
#   RECOMMENDED: Use the automated PowerShell script (handles timeouts, monitoring, and analysis):
#     powershell -NoProfile -ExecutionPolicy Bypass -File .\scripts\run-act-dast.ps1 -ScanProfile quick -Timeout 900
#     powershell -NoProfile -ExecutionPolicy Bypass -File .\scripts\run-act-dast.ps1 -ScanProfile full -Timeout 900
#     powershell -NoProfile -ExecutionPolicy Bypass -File .\scripts\run-act-dast.ps1 -ScanProfile deep -Timeout 1500
#
#   ALTERNATIVE: Direct act commands (manual monitoring required):
#     [Console]::OutputEncoding = [System.Text.Encoding]::UTF8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=quick --artifact-server-path ./dast-reports 2>&1 | Out-File -FilePath .\dast-reports\act-dast.log -Encoding utf8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=full --artifact-server-path ./dast-reports 2>&1 | Out-File -FilePath .\dast-reports\act-dast.log -Encoding utf8
#     act workflow_dispatch -W .github/workflows/dast.yml --input scan_profile=deep --artifact-server-path ./dast-reports 2>&1 | Out-File -FilePath .\dast-reports\act-dast.log -Encoding utf8
# MONITORING: Auto-monitor progress in separate terminal: .\scripts\monitor-act-dast.ps1
# MANUAL CHECK: Get-Content .\dast-reports\act-dast.log -Tail 100
# TIMING: Quick=3-5min, Full=10-15min, Deep=20-25min
# OUTPUT CONVENTION: All scan outputs and reports must be written to ./dast-reports/ directory

on:
  push:
    branches: [ main ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.github/copilot-instructions.md'
      - '.github/instructions/**'
      - 'dast-reports/**'
      - 'nohup.out'
      - 'LICENSE'
      - '.editorconfig'
      - '.gitignore'
      - '.gitattributes'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/pull_request_template.md'
      - '.github/dependabot.yml'
      - '**/*.log'
      - '**/*.sarif'
  pull_request:
    branches: [ main ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.github/copilot-instructions.md'
      - '.github/instructions/**'
      - 'dast-reports/**'
      - 'nohup.out'
      - 'LICENSE'
      - '.editorconfig'
      - '.gitignore'
      - '.gitattributes'
      - '.github/ISSUE_TEMPLATE/**'
      - '.github/pull_request_template.md'
      - '.github/dependabot.yml'
      - '**/*.log'
      - '**/*.sarif'
  schedule:
    # Run DAST weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      target_url:
        description: 'Target URL for DAST scanning (default: https://127.0.0.1:8080)'
        required: false
        default: 'https://127.0.0.1:8080'
      scan_profile:
        description: 'Scan profile for performance optimization'
        required: false
        default: 'full'
        type: choice
        options:
          - quick
          - full
          - deep

env:
  GO_VERSION: '1.25.1'

  SCAN_PROFILE: ${{ github.event.inputs.scan_profile || 'full' }}

  # HTTP endpoints use 127.0.0.1 (not localhost) for predictable IPv4 behavior and TLS certificate compatibility
  APP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}
  APP_PRIVATE_TARGET_URL: ${{ github.event.inputs.target_url || 'http://127.0.0.1:9090' }}

  # Nuclei runs inside GitHub Actions runner/act container - can use 127.0.0.1 directly
  NUCLEI_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}

  # ZAP runs in separate Docker container - must use host.docker.internal to reach host network
  ZAP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://127.0.0.1:8080' }}
  # ZAP_PUBLIC_TARGET_URL: ${{ github.event.inputs.target_url || 'https://host.docker.internal:8080' }}

  APP_BIND_PUBLIC_PROTOCOL: https
  APP_BIND_PUBLIC_ADDRESS: 0.0.0.0
  APP_BIND_PUBLIC_PORT: 8080

  APP_BIND_PRIVATE_PROTOCOL: http
  APP_BIND_PRIVATE_ADDRESS: 127.0.0.1
  APP_BIND_PRIVATE_PORT: 9090

  # Database uses localhost (not 127.0.0.1) for PostgreSQL client library optimization
  DB_HOST: localhost
  DB_PORT: 5432
  DB_NAME: DB
  DB_USER: USR
  DB_PASSWORD: PWD

jobs:
  dast-security-scan:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:18
        env:
          POSTGRES_DB: ${{ env.DB_NAME }}
          POSTGRES_PASSWORD: ${{ env.DB_PASSWORD }}
          POSTGRES_USER: ${{ env.DB_USER }}
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432 # env context is not available in the services.ports section

    permissions:
      contents: read
      security-events: write
      actions: read

    steps:
    - name: Workflow Start - CI - DAST Security Testing (ci-dast.yml)
      run: |
        echo "=========================================="
        echo "Workflow: CI - DAST Security Testing"
        echo "File: .github/workflows/ci-dast.yml"
        echo "Job: dast-security-scan"
        echo "Triggered by: ${{ github.event_name }}"
        echo "=========================================="

    - name: Checkout code
      uses: actions/checkout@v5.0.0

    - name: Setup directories and Nuclei templates version
      id: nuclei-version
      run: |
        # Create required directories
        mkdir -p ./dast-reports configs/test
        # Ephemeral mode: always use latest nuclei templates
        echo "templates_version=LATEST" >> $GITHUB_OUTPUT

    - name: Diagnostic - System information
      if: always()
      run: |
        mkdir -p ./dast-reports
        SYSINFO=dast-reports/system-info.txt
        echo "Date: $(date -u)" > $SYSINFO
        echo "===== uname -a =====" >> $SYSINFO
        uname -a >> $SYSINFO 2>&1 || true
        echo "\n===== lsb_release / os-release =====" >> $SYSINFO
        [ -f /etc/os-release ] && cat /etc/os-release >> $SYSINFO || true
        echo "\n===== docker version/info =====" >> $SYSINFO
        docker version >> $SYSINFO 2>&1 || true
        docker info >> $SYSINFO 2>&1 || true
        echo "\n===== docker network ls =====" >> $SYSINFO
        docker network ls >> $SYSINFO 2>&1 || true
        echo "\n===== docker ps -a =====" >> $SYSINFO
        docker ps -a >> $SYSINFO 2>&1 || true
        echo "\n===== Top processes (top -b -n1 | head -30) =====" >> $SYSINFO
        (top -b -n1 | head -30) >> $SYSINFO 2>&1 || ps aux --sort=-%mem | head -30 >> $SYSINFO 2>&1 || true
        echo "\n===== Selected environment variables =====" >> $SYSINFO
        # Print only non-secret env vars that are helpful for diagnostics
        for v in GO_VERSION SCAN_PROFILE APP_PUBLIC_TARGET_URL APP_PRIVATE_TARGET_URL NUCLEI_PUBLIC_TARGET_URL ZAP_PUBLIC_TARGET_URL APP_BIND_PUBLIC_PORT APP_BIND_PRIVATE_PORT DB_HOST DB_PORT; do
          echo "$v=${!v}" >> $SYSINFO 2>&1 || true
        done
        echo "\nWrote system diagnostics to: $SYSINFO"

    - name: Cache Nuclei Templates
      id: cache-nuclei-templates
      uses: actions/cache@v4
      with:
        path: /root/nuclei-templates
        key: nuclei-templates-${{ runner.os }}-${{ steps.nuclei-version.outputs.templates_version }}
        restore-keys: |
          nuclei-templates-${{ runner.os }}-

    - name: Set up Go
      uses: actions/setup-go@v6
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Pre-pull Docker images (parallel)
      run: |
        echo "🐳 Pre-pulling Docker images in parallel..."

        # Array of all images used in this workflow
        IMAGES=(
          "postgres:18"
          "ghcr.io/zaproxy/zaproxy:stable"
        )

        # Pull all images concurrently
        for image in "${IMAGES[@]}"; do
          echo "Pulling $image..."
          docker pull "$image" &
        done

        # Wait for all pulls to complete
        wait

        echo "✅ All images pre-pulled successfully"

    - name: Install dependencies
      run: go mod download

    - name: Build application
      run: go build -o cryptoutil ./cmd/cryptoutil

    # See internal\common\config\config.go for configuration options
    - name: Start application for DAST testing
      run: |
        # Create unseal secret and config files
        echo "dast-simple-unseal-secret-value-1" > ./configs/test/dast-simple-unseal-secret-value-1.secret
        cat > ./configs/test/config.yml <<EOF
        log-level: "DEBUG"
        verbose: true
        rate-limit: 1000
        bind-public-protocol: "${APP_BIND_PUBLIC_PROTOCOL}"
        bind-public-address: "${APP_BIND_PUBLIC_ADDRESS}"
        bind-public-port: ${APP_BIND_PUBLIC_PORT}
        bind-private-protocol: "${APP_BIND_PRIVATE_PROTOCOL}"
        bind-private-address: "${APP_BIND_PRIVATE_ADDRESS}"
        bind-private-port: ${APP_BIND_PRIVATE_PORT}
        database-url: "postgres://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}?sslmode=disable"
        unseal-mode: "1-of-1"
        unseal-files:
          - ./configs/test/dast-simple-unseal-secret-value-1.secret
        EOF

        # Start application in background, capture PID for cleanup; use nohup to avoid termination on shell exit
        mkdir -p dast-reports
        # Redirect stdout/stderr to files under dast-reports for easier post-mortem
        nohup ./cryptoutil server start --config configs/test/config.yml > dast-reports/cryptoutil.stdout 2> dast-reports/cryptoutil.stderr &
        APP_PID=$!
        echo "APP_PID=$APP_PID" >> $GITHUB_ENV
        echo "Wrote app logs to: dast-reports/cryptoutil.stdout and dast-reports/cryptoutil.stderr"

        # Enhanced readiness probe with retry/backoff logic
        echo "Waiting for application to be ready..."
        MAX_ATTEMPTS=30
        ATTEMPT=0
        BACKOFF=1
        READY=false

        # Progressive health check: private health endpoints first, then public Swagger
        HEALTH_ENDPOINTS=(
          "${{ env.APP_PRIVATE_TARGET_URL }}/readyz"
          # "${{ env.APP_PRIVATE_TARGET_URL }}/livez"
          # "${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        )

        while [ $ATTEMPT -lt $MAX_ATTEMPTS ] && [ "$READY" != "true" ]; do
          ATTEMPT=$((ATTEMPT + 1))
          echo "Attempt $ATTEMPT/$MAX_ATTEMPTS (backoff: ${BACKOFF}s)"

          for endpoint in "${HEALTH_ENDPOINTS[@]}"; do
            echo "Testing: $endpoint"
            # Use slightly generous timeouts for containerized environments
            # Save response headers and body to files for debugging
            SAFE_NAME=$(echo "$endpoint" | sed -e 's/[^a-zA-Z0-9]/_/g' | cut -c1-80)
            if curl -sk --connect-timeout 10 --max-time 15 -D dast-reports/health_${SAFE_NAME}.headers -o dast-reports/health_${SAFE_NAME}.body "$endpoint" >/dev/null 2>&1; then
              echo "✓ Application ready at: $endpoint (output saved to dast-reports/health_${SAFE_NAME}.*)"
              READY=true
              break
            else
              echo "✗ Not ready: $endpoint"
            fi
          done

          if [ "$READY" != "true" ]; then
            sleep $BACKOFF
            # Exponential backoff with max 5 seconds
            BACKOFF=$((BACKOFF < 5 ? BACKOFF + 1 : 5))
          fi
        done

        if [ "$READY" != "true" ]; then
          echo "❌ Application failed to become ready within timeout"
          exit 1
        fi

        echo "✅ Application is ready and responsive"

    - name: Diagnostic - Verify connectivity from runner and Docker contexts
      id: diagnostic_connectivity
      if: always()
      run: |
        # Diagnostic connectivity checks: quick reachability tests that return concise status codes.
        # Use consistent timeouts for all diagnostic curl calls.
        CURL_CONNECT_TIMEOUT=10
        CURL_MAX_TIMEOUT=15

        echo ""
        echo "🔍 Testing connectivity from runner..."
        echo ""

        echo "1. Testing ${{ env.APP_PRIVATE_TARGET_URL }}/readyz (readiness probe)"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D dast-reports/connectivity_private_readyz.headers -o dast-reports/connectivity_private_readyz.body ${{ env.APP_PRIVATE_TARGET_URL }}/readyz || true
        echo "Runner->private_readyz: $(wc -c < dast-reports/connectivity_private_readyz.body 2>/dev/null || echo 0) bytes"
        if [ -s dast-reports/connectivity_private_readyz.body ]; then
          echo "  ✅ ${{ env.APP_PRIVATE_TARGET_URL }} reachable from runner"
        else
          echo "  ❌ ${{ env.APP_PRIVATE_TARGET_URL }} NOT reachable from runner"
        fi

        echo "2. Testing ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D dast-reports/connectivity_public_swagger.headers -o dast-reports/connectivity_public_swagger.body ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json || true
        echo "Runner->public_swagger: $(wc -c < dast-reports/connectivity_public_swagger.body 2>/dev/null || echo 0) bytes"
        if [ -s dast-reports/connectivity_public_swagger.body ]; then
          echo "  ✅ ${{ env.APP_PUBLIC_TARGET_URL }} reachable from runner"
        else
          echo "  ❌ ${{ env.APP_PUBLIC_TARGET_URL }} NOT reachable from runner"
        fi

        echo "3. Testing Nuclei target ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D dast-reports/connectivity_nuclei.headers -o dast-reports/connectivity_nuclei.body ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ui/swagger/doc.json || true
        echo "Runner->nuclei_swagger: $(wc -c < dast-reports/connectivity_nuclei.body 2>/dev/null || echo 0) bytes"
        if [ -s dast-reports/connectivity_nuclei.body ]; then
          echo "  ✅ Nuclei target reachable from runner"
          echo "NUCLEI_REACHABLE=true" >> $GITHUB_ENV
          echo "NUCLEI_REACHABLE=true" >> $GITHUB_OUTPUT
        else
          echo "  ❌ Nuclei target NOT reachable from runner"
          # Also test the root endpoint as fallback
          echo "  Testing fallback: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/"
          curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D dast-reports/connectivity_nuclei_fallback.headers -o dast-reports/connectivity_nuclei_fallback.body ${{ env.NUCLEI_PUBLIC_TARGET_URL }}/ || true
          if [ -s dast-reports/connectivity_nuclei_fallback.body ]; then
            echo "  ✅ Nuclei target reachable via fallback endpoint"
            echo "NUCLEI_REACHABLE=true" >> $GITHUB_ENV
            echo "NUCLEI_REACHABLE=true" >> $GITHUB_OUTPUT
          else
            echo "  ❌ Nuclei target NOT reachable from runner (including fallback)"
            echo "NUCLEI_REACHABLE=false" >> $GITHUB_ENV
            echo "NUCLEI_REACHABLE=false" >> $GITHUB_OUTPUT
          fi
        fi

        echo ""
        echo "🔍 Testing connectivity from Docker container..."
        echo ""

        echo "4. Testing ${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json"
        # Test only the configured ZAP_PUBLIC_TARGET_URL from Docker context
        OUTFILE=dast-reports/docker_connect_$(echo "${{ env.ZAP_PUBLIC_TARGET_URL }}" | sed -e 's/[^a-zA-Z0-9]/_/g').txt
        if curl -sk --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT -D - "${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json" > $OUTFILE 2>&1; then
          echo "  ✅ ${{ env.ZAP_PUBLIC_TARGET_URL }} reachable from Docker container (details: $OUTFILE)"
          echo "ZAP_REACHABLE=true" >> $GITHUB_ENV
          echo "ZAP_REACHABLE=true" >> $GITHUB_OUTPUT
        else
          echo "  ❌ ${{ env.ZAP_PUBLIC_TARGET_URL }} NOT reachable from Docker container (details: $OUTFILE)"
          echo "ZAP_REACHABLE=false" >> $GITHUB_ENV
          echo "ZAP_REACHABLE=false" >> $GITHUB_OUTPUT
        fi

        echo "5. Testing ${{ env.APP_PUBLIC_TARGET_URL }} from Docker:"
        if curl -skf --connect-timeout $CURL_CONNECT_TIMEOUT --max-time $CURL_MAX_TIMEOUT ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json -o /dev/null -w "HTTP %{http_code}\n" 2>&1; then
          echo "  ✅ ${{ env.APP_PUBLIC_TARGET_URL }} reachable from Docker"
        else
          echo "  ❌ ${{ env.APP_PUBLIC_TARGET_URL }} NOT reachable from Docker"
        fi

        echo ""
        echo "=== Summary ==="
        echo "- ACT public target URL should use: ${{ env.APP_PUBLIC_TARGET_URL }}"
        echo "- ACT private target URL should use: ${{ env.APP_PRIVATE_TARGET_URL }}"
        echo "- Nuclei public target URL should use: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}"
        echo "- ZAP public target URL should use: ${{ env.ZAP_PUBLIC_TARGET_URL }}"

    - name: Capture baseline response headers (immediate)
      if: always()
      run: |
        # Capture headers from key API endpoints (app is ready per health check)
        # NOTE: -v flag enables verbose output showing request headers (add back if debugging needed)
        echo "Starting header capture from ${{ env.APP_PUBLIC_TARGET_URL }}..."
        echo "Current directory: $(pwd)"
        echo "Contents of dast-reports before capture:"
        ls -la dast-reports/ || echo "dast-reports directory not found"

        echo "Creating header baseline file: dast-reports/response-headers.txt"
        {
          echo "# Header Baseline ($(date -u))"

          echo "## Private - readyz"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PRIVATE_TARGET_URL }}/readyz 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PRIVATE_TARGET_URL }}/readyz - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo -e "\n## Private - livez"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PRIVATE_TARGET_URL }}/livez 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PRIVATE_TARGET_URL }}/livez - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo "## Swagger UI (main page)"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/ 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo -e "\n## Swagger API spec (doc.json)"
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: ${{ env.APP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo -e "\n## Browser API - CSRF token endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/browser/api/v1/csrf-token"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo -e "\n## Browser API - Elastic Keys endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/browser/api/v1/elastickeys"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2

          echo -e "\n## Service API - Elastic Keys endpoint"
          REQUEST_URL="${{ env.APP_PUBLIC_TARGET_URL }}/service/api/v1/elastickeys"
          echo "  Request URL: $REQUEST_URL" >&2
          echo "  Request headers sent by curl -sk (GET with body discarded):" >&2
          HTTP_CODE=$(curl -sk -o /dev/null -D /dev/stderr -w "%{http_code}" "$REQUEST_URL" 2>&1 | tee /dev/stderr | tail -1)
          echo "  Console: $REQUEST_URL - HTTP $HTTP_CODE" >&2
          [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 400 ] && echo "  ✅ Success" >&2 || echo "  ❌ Failed" >&2
        } > dast-reports/response-headers.txt

        echo "Verifying file creation: dast-reports/response-headers.txt"
        if [ -f "dast-reports/response-headers.txt" ]; then
          echo "File created successfully: dast-reports/response-headers.txt"
          echo "File size: $(wc -c < dast-reports/response-headers.txt) bytes"
          echo "File contents preview (first 2 lines):"
          echo "########################################"
          head -2 dast-reports/response-headers.txt
          echo "########################################"
        else
          echo "File NOT created: dast-reports/response-headers.txt"
        fi

        echo "Contents of dast-reports after capture: dast-reports/response-headers.txt"
        ls -la dast-reports/ || echo "dast-reports directory not found"

        echo "Header capture process completed: dast-reports/response-headers.txt"
        # Also capture a short app log tail for quick inspection
        if [ -f dast-reports/cryptoutil.stdout ]; then
          echo "\n===== APP STDOUT (tail 200) =====" >> dast-reports/system-info.txt || true
          tail -n 200 dast-reports/cryptoutil.stdout >> dast-reports/system-info.txt || true
        fi
        if [ -f dast-reports/cryptoutil.stderr ]; then
          echo "\n===== APP STDERR (tail 200) =====" >> dast-reports/system-info.txt || true
          tail -n 200 dast-reports/cryptoutil.stderr >> dast-reports/system-info.txt || true
        fi

    # Official ZAP actions for both GitHub-hosted runners and act-local
    - name: Run OWASP ZAP DAST Scan
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      continue-on-error: true  # ZAP exit code 3 (informational findings) treated as failure by action
      uses: zaproxy/action-full-scan@v0.13.0
      with:
        target: ${{ env.ZAP_PUBLIC_TARGET_URL }}
        docker_name: 'ghcr.io/zaproxy/zaproxy:stable'
        rules_file_name: '.zap/rules.tsv'
        # Cookie ignore list: Only _csrf in cryptoutil; JSESSIONID and csrftoken are from other stacks
        # -d: debug/verbose logging, all -config options must be inside -z quotes
        cmd_options: '-a -j -m 5 -T 30 -d -r zap-report.html -w zap-report.md -x zap-report.xml -J zap-report.json -z "-config rules.cookie.ignorelist=_csrf -config api.addrs.addr.name=.* -config api.addrs.addr.regex=true -config connection.hostHeader=127.0.0.1:8080"'
        allow_issue_writing: false
        artifact_name: 'zap-report'
        fail_action: 'false'  # Only controls exit code 1/2, not 3

    - name: Collect ZAP DAST Scan artifacts
      if: always()
      run: |
        echo "Collecting ZAP Full Scan artifacts..."
        for artifact in zap-report.{html,json,xml,md} report_json.json report_md.md report_html.html; do
          if [ -f "./dast-reports/$artifact" ]; then
            echo "  ✅ Already exists: dast-reports/$artifact"
          elif [ -f "$artifact" ]; then
            # Move ZAP full scan artifacts to dast-reports
            if mv "$artifact" ./dast-reports/; then
              echo "  ✅ Moved: $artifact -> dast-reports/"
            else
              echo "  ❌ Failed to move: $artifact"
            fi
          else
            echo "  ⏭ Not found: $artifact (skipped)"
          fi
        done
        echo "ZAP DAST scan artifact collection completed"

    - name: Run OWASP ZAP API Scan
      if: ${{ steps.diagnostic_connectivity.outputs.ZAP_REACHABLE == 'true' }}
      continue-on-error: true  # ZAP exit code 3 (informational findings) treated as failure by action
      uses: zaproxy/action-api-scan@v0.10.0
      with:
        target: '${{ env.ZAP_PUBLIC_TARGET_URL }}/ui/swagger/doc.json'
        docker_name: 'ghcr.io/zaproxy/zaproxy:stable'
        format: openapi
        cmd_options: '-a -j -T 30 -r zap-api-report.html -J zap-api-report.json -z "-config connection.hostHeader=127.0.0.1:8080"'
        fail_action: 'false'  # Only controls exit code 1/2, not 3
        allow_issue_writing: false
        artifact_name: 'zap-api-report'

    - name: Collect ZAP API Scan artifacts
      if: always()
      run: |
        echo "Collecting ZAP API Scan artifacts..."
        # Move ZAP API scan artifacts to dast-reports immediately after generation
        for artifact in zap-api-report.{html,json} report_json.json report_md.md report_html.html; do
          if [ -f "./dast-reports/$artifact" ]; then
            echo "  ✅ Already exists: dast-reports/$artifact (skipped)"
          elif [ -f "$artifact" ]; then
            if mv "$artifact" ./dast-reports/; then
              echo "  ✅ Moved: $artifact -> dast-reports/"
            else
              echo "  ❌ Failed to move: $artifact"
            fi
          else
            echo "  ⏭ Not found: $artifact (skipped)"
          fi
        done
        echo "ZAP API scan artifact collection completed"

    # Doc: https://github.com/projectdiscovery/nuclei-action
    # NOTE: Nuclei runs via composite action inside the GitHub Actions runner/act container,
    # so it can access 127.0.0.1:8080 directly without Docker networking complications.
    - name: Set Nuclei scan configuration based on profile
      id: nuclei_config
      run: |
        case "$SCAN_PROFILE" in
          "quick")
            echo "timeout=60" >> $GITHUB_OUTPUT
            echo "concurrency=12" >> $GITHUB_OUTPUT
            echo "rate_limit=100" >> $GITHUB_OUTPUT
            echo "templates=cves/2023/,cves/2024/,vulnerabilities/,security-misconfiguration/generic/" >> $GITHUB_OUTPUT
            echo "description=Quick scan (PRs): ~2-3 minutes, recent CVEs and basic misconfigurations" >> $GITHUB_OUTPUT
            ;;
          "deep")
            echo "timeout=1200" >> $GITHUB_OUTPUT
            echo "concurrency=32" >> $GITHUB_OUTPUT
            echo "rate_limit=300" >> $GITHUB_OUTPUT
            echo "templates=" >> $GITHUB_OUTPUT
            echo "description=Deep scan (scheduled): ~15-20 minutes, all templates" >> $GITHUB_OUTPUT
            ;;
          *) # full (default)
            echo "timeout=600" >> $GITHUB_OUTPUT
            echo "concurrency=24" >> $GITHUB_OUTPUT
            echo "rate_limit=200" >> $GITHUB_OUTPUT
            echo "templates=cves/,vulnerabilities/,security-misconfiguration/,default-logins/,exposed-panels/" >> $GITHUB_OUTPUT
            echo "description=Full scan (main push): ~8-10 minutes, comprehensive coverage" >> $GITHUB_OUTPUT
            ;;
        esac
        echo "Profile: $SCAN_PROFILE"
        echo "Configuration set for profile: $SCAN_PROFILE"

    - name: Nuclei - Vulnerability Scan (${{ steps.nuclei_config.outputs.description }})
      if: ${{ steps.diagnostic_connectivity.outputs.NUCLEI_REACHABLE == 'true' }}
      id: nuclei_scan
      uses: projectdiscovery/nuclei-action@main
      continue-on-error: true  # Continue even if nuclei finds vulnerabilities (exit code 1) or has errors
      with:
        target: ${{ env.NUCLEI_PUBLIC_TARGET_URL }}
        user-agent: "User-Agent:'Nuclei - Vulnerability Scan (Have a nice day)'"
        # Exclude tcp/javascript protocol templates to avoid scanning infrastructure services (SSH:22, PostgreSQL:5432, RPC:111)
        # See: https://github.com/orgs/projectdiscovery/discussions/5159
        # Use .nuclei-ignore file to suppress known false positives
        flags: "-c ${{ steps.nuclei_config.outputs.concurrency }} -rl ${{ steps.nuclei_config.outputs.rate_limit }} -timeout ${{ steps.nuclei_config.outputs.timeout }} -stats -ept tcp,javascript -ei .nuclei-ignore${{ steps.nuclei_config.outputs.templates && format(' -t {0}', steps.nuclei_config.outputs.templates) || '' }}"

    - name: Set dummy token for local act runs
      if: ${{ github.actor == 'nektos/act' }}
      run: |
        if [ -n "${GITHUB_TOKEN}" ]; then
          echo "GITHUB_TOKEN already set; leaving existing token in place";
        else
          echo "Setting dummy GITHUB_TOKEN for act local run to avoid upload-sarif failure";
          echo "GITHUB_TOKEN=act-dummy-token" >> $GITHUB_ENV;
        fi

    - name: Collect Nuclei scan artifacts
      if: always()
      run: |
        # Move Nuclei artifacts to dast-reports
        [ -f "nuclei.log" ] && mv nuclei.log ./dast-reports/ || true
        [ -f "nuclei.sarif" ] && mv nuclei.sarif ./dast-reports/ || true
        [ -f "nuclei-templates.version" ] && mv nuclei-templates.version ./dast-reports/ || true

        # For GitHub runs, copy SARIF back to root for upload-sarif action
        if [ "${{ github.actor }}" != "nektos/act" ] && [ -f "./dast-reports/nuclei.sarif" ]; then
          cp ./dast-reports/nuclei.sarif nuclei.sarif
        fi
        echo "Nuclei scan artifacts collected"

    - name: Post-collect artifact listing
      if: always()
      run: |
        echo "Artifact collection complete"
        # Produce a short diagnostic listing of artifacts for easier analysis
        echo "===== DAST-REPORTS DIR =====" > dast-reports/artifact-listing.txt
        ls -la dast-reports/ >> dast-reports/artifact-listing.txt 2>&1 || true
          echo "Wrote artifact listing to dast-reports/artifact-listing.txt"

    - name: Capture container logs
      if: always()
      run: |
        echo "Capturing Docker container logs for debugging..."
        mkdir -p dast-reports/container-logs

        # List all containers for reference
        echo "=== Docker Containers ===" > dast-reports/container-logs/containers.txt
        docker ps -a --format "table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}" >> dast-reports/container-logs/containers.txt 2>&1 || echo "No containers found or docker not available" >> dast-reports/container-logs/containers.txt

        # Capture logs from relevant containers (ZAP, postgres service containers, etc.)
        # Use a broad pattern to catch any containers that might be related
        for container in $(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "(zap|postgres|cryptoutil|grafana|otel|compose)" | head -20); do
          echo "Capturing logs for container: $container"
          if docker logs "$container" > "dast-reports/container-logs/${container}.log" 2>&1; then
            echo "✅ Successfully captured logs for: $container ($(wc -l < "dast-reports/container-logs/${container}.log") lines)"
          else
            echo "❌ Failed to capture logs for: $container" >> dast-reports/container-logs/errors.txt
          fi
        done

        # Also capture Docker system information
        docker info > dast-reports/container-logs/docker-info.txt 2>&1 || echo "Docker info not available" > dast-reports/container-logs/docker-info.txt
        docker system df > dast-reports/container-logs/docker-df.txt 2>&1 || echo "Docker system df not available" > dast-reports/container-logs/docker-df.txt

        echo "Container log capture completed"

    - name: Upload container logs
      if: always()
      uses: actions/upload-artifact@v5.0.0
      with:
        name: container-logs
        path: dast-reports/container-logs/
        retention-days: 1

    - name: GitHub Workflow artifacts
      if: ${{ github.actor != 'nektos/act' }}
      uses: actions/upload-artifact@v5.0.0
      with:
        name: dast-reports
        path: |
          dast-reports/nuclei.log
          dast-reports/nuclei.sarif
          dast-reports/response-headers.txt
        retention-days: 2

    - name: GitHub Security Dashboard Alerts update
      uses: github/codeql-action/upload-sarif@v3
      # Skip entirely when running under act; also ensure SARIF file actually exists
      if: ${{ github.actor != 'nektos/act' && hashFiles('nuclei.sarif') != '' }}
      with:
        sarif_file: nuclei.sarif
      env:
        # Use real token in GitHub hosted runner
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate Security Summary
      if: always()
      run: |
        SUMMARY_FILE=dast-reports/act-status.txt
        {
          echo "# DAST Security Scan Results"
          echo ""
          echo "**Profile:** ${{ env.SCAN_PROFILE }} (${{ steps.nuclei_config.outputs.description }})"
          echo "**Nuclei Target:** ${{ env.NUCLEI_PUBLIC_TARGET_URL }} | **ZAP Target:** ${{ env.ZAP_PUBLIC_TARGET_URL }}"
          echo "**Date:** $(date -u)"
          echo ""
          echo "## Scan Coverage"
          [ -f "dast-reports/nuclei.log" ] && echo "- ✅ **Nuclei Scan**" || echo "- ⏭ **Nuclei Scan:** Skipped"
          ls zap-*-report.html >/dev/null 2>&1 && echo "- ✅ **OWASP ZAP Scans**" || echo "- ⏭ **OWASP ZAP Scans:** Disabled"
          echo ""
          echo "## Generated Reports"
          [ -f dast-reports/nuclei.log ] && echo "- Nuclei Log/SARIF" || true
          [ -f dast-reports/response-headers.txt ] && echo "- Security Headers" || true
          ls zap-*-report.html >/dev/null 2>&1 && echo "- ZAP Reports" || true
          echo ""
          echo "## Diagnostic summary"
          echo "NUCLEI_REACHABLE=${NUCLEI_REACHABLE:-unset}"
          echo "ZAP_REACHABLE=${ZAP_REACHABLE:-unset}"
          echo "APP_PID=${APP_PID:-unset}"
          echo "APP_LOGS: dast-reports/cryptoutil.stdout (exists=$( [ -f dast-reports/cryptoutil.stdout ] && echo yes || echo no))"
          echo "APP_ERRS: dast-reports/cryptoutil.stderr (exists=$( [ -f dast-reports/cryptoutil.stderr ] && echo yes || echo no))"
          echo "System diagnostics file: dast-reports/system-info.txt"
        } | tee -a $GITHUB_STEP_SUMMARY > $SUMMARY_FILE
        echo "Wrote final analysis summary to: $SUMMARY_FILE"

    - name: Cleanup
      if: always()
      run: |
        # Stop application
        [ -n "${APP_PID:-}" ] && { kill "$APP_PID" 2>/dev/null || true; sleep 1; kill -9 "$APP_PID" 2>/dev/null || true; }
